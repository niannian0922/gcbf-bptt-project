#!/usr/bin/env python3
"""
ğŸš€ åŠ¨æ€åä½œä¿®å¤
ç¡®ä¿æ™ºèƒ½ä½“æœ‰æ˜æ˜¾è¿åŠ¨ï¼ŒåŒæ—¶ä¿æŒåœ¨ç”»é¢å†…
å¹³è¡¡åŠ¨æ€æ€§å’Œè¾¹ç•Œæ§åˆ¶
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import yaml
import os
from datetime import datetime

def create_dynamic_collaboration():
    """åˆ›å»ºçœŸæ­£åŠ¨æ€çš„åä½œå¯è§†åŒ–"""
    print("ğŸš€ åŠ¨æ€åä½œä¿®å¤ç³»ç»Ÿ")
    print("=" * 50)
    print("ğŸ¯ ç›®æ ‡: ç¡®ä¿æ™ºèƒ½ä½“æœ‰æ˜æ˜¾è¿åŠ¨")
    print("ğŸš å†…å®¹: åŠ¨æ€æ— äººæœºç¼–é˜Ÿåä½œ")
    print("âš–ï¸ å¹³è¡¡: åŠ¨æ€æ€§ + è¾¹ç•Œæ§åˆ¶")
    print("=" * 50)
    
    # å¹³è¡¡çš„é…ç½®
    config = {
        'env': {
            'name': 'DoubleIntegrator',
            'num_agents': 6,
            'area_size': 4.0,
            'dt': 0.03,  # é€‚ä¸­çš„æ—¶é—´æ­¥é•¿
            'mass': 0.2,  # é€‚ä¸­çš„è´¨é‡
            'agent_radius': 0.15,
            'comm_radius': 1.0,
            'max_force': 1.0,  # æ¢å¤åˆç†çš„æœ€å¤§åŠ›
            'max_steps': 150,
            'social_radius': 0.4,
            'obstacles': {
                'enabled': True,
                'count': 2,
                'positions': [[0, 0.7], [0, -0.7]],
                'radii': [0.3, 0.3]
            }
        }
    }
    
    try:
        # å¯¼å…¥
        from gcbfplus.env import DoubleIntegratorEnv
        from gcbfplus.env.multi_agent_env import MultiAgentState
        from gcbfplus.policy.bptt_policy import create_policy_from_config
        
        print("âœ… å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºç¯å¢ƒ
        device = torch.device('cpu')
        env = DoubleIntegratorEnv(config['env'])
        env = env.to(device)
        
        print(f"âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
        print(f"   ğŸ“Š è§‚æµ‹ç»´åº¦: {env.observation_shape}")
        print(f"   âš¡ æœ€å¤§åŠ›: {env.max_force}")
        print(f"   â° æ—¶é—´æ­¥é•¿: {env.dt}")
        
        # åˆ›å»ºçœŸå®çš„åä½œåœºæ™¯
        initial_state = create_realistic_scenario(device, config['env']['num_agents'])
        
        print("âœ… ç°å®åä½œåœºæ™¯åˆ›å»ºæˆåŠŸ")
        
        # è¿è¡Œå¼ºåŒ–åŠ¨æ€æ¨¡æ‹Ÿ
        trajectory_data = run_dynamic_simulation(env, initial_state, config)
        
        print(f"âœ… åŠ¨æ€æ¨¡æ‹Ÿå®Œæˆ: {len(trajectory_data['positions'])} æ­¥")
        
        # ç”ŸæˆçœŸæ­£åŠ¨æ€çš„å¯è§†åŒ–
        output_file = create_dynamic_visualization(trajectory_data, config)
        
        print(f"ğŸ‰ åŠ¨æ€å¯è§†åŒ–å®Œæˆ: {output_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_realistic_scenario(device, num_agents):
    """åˆ›å»ºç°å®çš„åä½œåœºæ™¯"""
    from gcbfplus.env.multi_agent_env import MultiAgentState
    
    # ç°å®çš„èµ·å§‹å’Œç›®æ ‡ä½ç½®
    positions = torch.zeros(1, num_agents, 2, device=device)
    velocities = torch.zeros(1, num_agents, 2, device=device)
    goals = torch.zeros(1, num_agents, 2, device=device)
    
    # å·¦ä¾§ç¼–é˜Ÿï¼Œéœ€è¦æ˜æ˜¾ç§»åŠ¨åˆ°å³ä¾§
    start_x = -2.2
    target_x = 2.2
    
    print(f"   ğŸ“ è®¾ç½®ç¼–é˜Ÿåœºæ™¯:")
    print(f"      èµ·å§‹åŒºåŸŸ: x = {start_x}")
    print(f"      ç›®æ ‡åŒºåŸŸ: x = {target_x}")
    print(f"      ç§»åŠ¨è·ç¦»: {abs(target_x - start_x):.1f}")
    
    for i in range(num_agents):
        # Vå­—å½¢ç¼–é˜Ÿ
        if i == 0:
            # é¢†é˜Ÿ
            start_pos = [start_x, 0]
            target_pos = [target_x, 0]
        else:
            # åƒšæœº
            side = 1 if i % 2 == 1 else -1
            rank = (i + 1) // 2
            start_pos = [start_x - rank * 0.15, side * rank * 0.35]
            target_pos = [target_x + rank * 0.15, side * rank * 0.35]
        
        positions[0, i] = torch.tensor(start_pos, device=device)
        goals[0, i] = torch.tensor(target_pos, device=device)
        
        print(f"      æ— äººæœº{i+1}: {start_pos} â†’ {target_pos}")
    
    return MultiAgentState(
        positions=positions,
        velocities=velocities,
        goals=goals,
        batch_size=1
    )

def run_dynamic_simulation(env, initial_state, config):
    """è¿è¡ŒåŠ¨æ€æ¨¡æ‹Ÿ - ç¡®ä¿æœ‰æ˜æ˜¾è¿åŠ¨"""
    num_steps = 120
    
    trajectory_data = {
        'positions': [],
        'velocities': [],
        'actions': [],
        'goal_distances': [],
        'step_movements': [],
        'collaboration_scores': [],
        'config': config
    }
    
    current_state = initial_state
    previous_positions = initial_state.positions[0].cpu().numpy()
    
    print(f"   ğŸ¬ å¼€å§‹åŠ¨æ€æ¨¡æ‹Ÿ...")
    
    for step in range(num_steps):
        positions = current_state.positions[0].cpu().numpy()
        velocities = current_state.velocities[0].cpu().numpy()
        goal_positions = current_state.goals[0].cpu().numpy()
        
        trajectory_data['positions'].append(positions.copy())
        trajectory_data['velocities'].append(velocities.copy())
        
        # è®¡ç®—æ™ºèƒ½åŠ¨ä½œï¼ˆç¡®ä¿æœ‰è¿åŠ¨ï¼‰
        actions = compute_intelligent_actions(positions, velocities, goal_positions, 
                                            config['env']['obstacles'], 
                                            config['env']['social_radius'])
        
        # è½¬æ¢ä¸ºtensor
        actions_tensor = torch.tensor(actions, device=current_state.positions.device).unsqueeze(0)
        alphas = torch.ones(1, len(positions), device=current_state.positions.device) * 0.5
        
        trajectory_data['actions'].append(actions.copy())
        
        # è®¡ç®—æ­¥è¿›è¿åŠ¨è·ç¦»
        if step > 0:
            step_movement = np.linalg.norm(positions - previous_positions, axis=1)
            trajectory_data['step_movements'].append(step_movement)
        else:
            trajectory_data['step_movements'].append(np.zeros(len(positions)))
        
        previous_positions = positions.copy()
        
        # ç›®æ ‡è·ç¦»
        goal_distances = [np.linalg.norm(positions[i] - goal_positions[i]) 
                         for i in range(len(positions))]
        trajectory_data['goal_distances'].append(goal_distances)
        
        # åä½œå¾—åˆ†
        social_distances = []
        for i in range(len(positions)):
            for j in range(i+1, len(positions)):
                dist = np.linalg.norm(positions[i] - positions[j])
                social_distances.append(dist)
        
        if social_distances:
            min_dist = min(social_distances)
            social_radius = config['env']['social_radius']
            collab_score = min(min_dist / social_radius, 1.0)
        else:
            collab_score = 1.0
        
        trajectory_data['collaboration_scores'].append(collab_score)
        
        # ç¯å¢ƒæ­¥è¿›
        try:
            step_result = env.step(current_state, actions_tensor, alphas)
            current_state = step_result.next_state
            
            # è½¯è¾¹ç•Œ - å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œè½»æ¨å›æ¥
            current_positions = current_state.positions.clone()
            boundary = 2.8
            
            for i in range(current_positions.shape[1]):
                for j in range(2):  # x, y
                    if current_positions[0, i, j] > boundary:
                        current_positions[0, i, j] = boundary - 0.1
                    elif current_positions[0, i, j] < -boundary:
                        current_positions[0, i, j] = -boundary + 0.1
            
            current_state = MultiAgentState(
                positions=current_positions,
                velocities=current_state.velocities,
                goals=current_state.goals,
                batch_size=current_state.batch_size
            )
            
            # æ˜¾ç¤ºè¿›åº¦
            if step % 20 == 0:
                avg_goal_dist = np.mean(goal_distances)
                avg_movement = np.mean(trajectory_data['step_movements'][-1])
                action_mag = np.mean([np.linalg.norm(a) for a in actions])
                print(f"   æ­¥éª¤ {step:3d}: è¿åŠ¨={avg_movement:.4f}, åŠ¨ä½œ={action_mag:.3f}, ç›®æ ‡è·ç¦»={avg_goal_dist:.3f}")
            
            # æ£€æŸ¥å®Œæˆ
            if np.mean(goal_distances) < 0.4:
                print(f"   ğŸ¯ ç¼–é˜Ÿåˆ°è¾¾ç›®æ ‡! (æ­¥æ•°: {step+1})")
                break
                
        except Exception as e:
            print(f"   âš ï¸ ç¯å¢ƒæ­¥è¿›å¤±è´¥: {e}")
            break
    
    # è¿åŠ¨åˆ†æ
    total_movements = [sum(movements) for movements in zip(*trajectory_data['step_movements'])]
    avg_total_movement = np.mean(total_movements)
    
    print(f"   ğŸ“Š è¿åŠ¨åˆ†æ:")
    print(f"      å¹³å‡æ€»è¿åŠ¨è·ç¦»: {avg_total_movement:.3f}")
    print(f"      è¿åŠ¨çŠ¶æ€: {'âœ… åŠ¨æ€' if avg_total_movement > 1.0 else 'âŒ é™æ€'}")
    
    return trajectory_data

def compute_intelligent_actions(positions, velocities, goals, obstacles, social_radius):
    """è®¡ç®—æ™ºèƒ½åŠ¨ä½œ - ç¡®ä¿æœ‰è¿åŠ¨"""
    actions = np.zeros_like(positions)
    
    for i in range(len(positions)):
        # 1. ç›®æ ‡å¸å¼•åŠ›
        goal_direction = goals[i] - positions[i]
        goal_distance = np.linalg.norm(goal_direction)
        
        if goal_distance > 0.1:
            goal_force = (goal_direction / goal_distance) * min(goal_distance * 1.2, 0.8)
        else:
            goal_force = np.zeros(2)
        
        # 2. éšœç¢ç‰©æ’æ–¥åŠ›
        obstacle_force = np.zeros(2)
        for obs_pos, obs_radius in zip(obstacles['positions'], obstacles['radii']):
            obs_vec = positions[i] - np.array(obs_pos)
            obs_distance = np.linalg.norm(obs_vec)
            
            if obs_distance < obs_radius + 0.8:  # å½±å“èŒƒå›´
                if obs_distance > 0.01:
                    repulsion_strength = (obs_radius + 0.8 - obs_distance) / 0.8
                    obstacle_force += (obs_vec / obs_distance) * repulsion_strength * 0.6
        
        # 3. ç¤¾äº¤åŠ›ï¼ˆç»´æŒç¼–é˜Ÿï¼‰
        social_force = np.zeros(2)
        for j in range(len(positions)):
            if i != j:
                diff = positions[i] - positions[j]
                distance = np.linalg.norm(diff)
                
                if distance < social_radius and distance > 0.01:
                    # è½»å¾®æ’æ–¥ä»¥ç»´æŒè·ç¦»
                    social_force += (diff / distance) * 0.2
                elif distance > social_radius * 1.5 and distance > 0.01:
                    # è½»å¾®å¸å¼•ä»¥ä¿æŒç¼–é˜Ÿ
                    social_force -= (diff / distance) * 0.1
        
        # 4. é€Ÿåº¦é˜»å°¼ï¼ˆé˜²æ­¢è¿‡å¿«ï¼‰
        velocity_damping = -velocities[i] * 0.1
        
        # åˆæˆåŠ¨ä½œ
        total_force = goal_force + obstacle_force + social_force + velocity_damping
        
        # é™åˆ¶åŠ¨ä½œå¤§å°ä½†ä¿è¯æœ‰æ•ˆ
        force_magnitude = np.linalg.norm(total_force)
        if force_magnitude > 1.0:
            total_force = total_force / force_magnitude * 1.0
        elif force_magnitude < 0.05 and goal_distance > 0.2:
            # ç¡®ä¿æœ€å°åŠ¨ä½œä»¥ä¿è¯è¿åŠ¨
            total_force = (goal_direction / max(goal_distance, 0.01)) * 0.05
        
        actions[i] = total_force
    
    return actions

def create_dynamic_visualization(trajectory_data, config):
    """åˆ›å»ºçœŸæ­£åŠ¨æ€çš„å¯è§†åŒ–"""
    positions_history = trajectory_data['positions']
    if not positions_history:
        return None
    
    num_agents = len(positions_history[0])
    num_steps = len(positions_history)
    obstacles = config['env']['obstacles']
    
    # åˆ†æè¿åŠ¨èŒƒå›´
    all_positions = np.concatenate(positions_history, axis=0)
    min_x, max_x = all_positions[:, 0].min() - 0.3, all_positions[:, 0].max() + 0.3
    min_y, max_y = all_positions[:, 1].min() - 0.3, all_positions[:, 1].max() + 0.3
    
    # ç¡®ä¿åˆç†çš„æ˜¾ç¤ºèŒƒå›´
    center_x = (min_x + max_x) / 2
    center_y = (min_y + max_y) / 2
    range_x = max(max_x - min_x, 3.0)
    range_y = max(max_y - min_y, 2.0)
    
    display_min_x = center_x - range_x / 2
    display_max_x = center_x + range_x / 2
    display_min_y = center_y - range_y / 2
    display_max_y = center_y + range_y / 2
    
    print(f"   ğŸ“ åŠ¨æ€æ˜¾ç¤ºèŒƒå›´:")
    print(f"      X: [{display_min_x:.2f}, {display_max_x:.2f}]")
    print(f"      Y: [{display_min_y:.2f}, {display_max_y:.2f}]")
    
    # åˆ›å»ºå›¾å½¢
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))
    fig.suptitle('ğŸš€ åŠ¨æ€æ— äººæœºç¼–é˜Ÿåä½œ - ç¡®ä¿è¿åŠ¨ç‰ˆ', fontsize=16, fontweight='bold')
    
    # ä¸»è½¨è¿¹å›¾
    ax1.set_xlim(display_min_x, display_max_x)
    ax1.set_ylim(display_min_y, display_max_y)
    ax1.set_aspect('equal')
    ax1.set_title('ğŸš åŠ¨æ€æ— äººæœºç¼–é˜Ÿåä½œ')
    ax1.grid(True, alpha=0.3)
    
    # ç»˜åˆ¶éšœç¢ç‰©
    for i, (pos, radius) in enumerate(zip(obstacles['positions'], obstacles['radii'])):
        circle = plt.Circle(pos, radius, color='red', alpha=0.8, 
                          label='éšœç¢ç‰©' if i == 0 else "")
        ax1.add_patch(circle)
    
    # ç»˜åˆ¶èµ·å§‹å’Œç›®æ ‡åŒºåŸŸ
    start_zone = plt.Rectangle((-2.5, -1.5), 0.6, 3.0, fill=False, 
                              edgecolor='green', linestyle='--', linewidth=2, 
                              alpha=0.7, label='èµ·å§‹åŒºåŸŸ')
    ax1.add_patch(start_zone)
    
    target_zone = plt.Rectangle((1.9, -1.5), 0.6, 3.0, fill=False, 
                               edgecolor='blue', linestyle='--', linewidth=2, 
                               alpha=0.7, label='ç›®æ ‡åŒºåŸŸ')
    ax1.add_patch(target_zone)
    
    # æ— äººæœºé¢œè‰²
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#FF9FF3']
    
    # åˆå§‹åŒ–åŠ¨ç”»å…ƒç´ 
    trail_lines = []
    drone_dots = []
    velocity_arrows = []
    
    for i in range(num_agents):
        # è½¨è¿¹çº¿
        line, = ax1.plot([], [], '-', color=colors[i], alpha=0.8, linewidth=3)
        trail_lines.append(line)
        
        # æ— äººæœºï¼ˆä¸‰è§’å½¢è¡¨ç¤ºæ–¹å‘ï¼‰
        drone, = ax1.plot([], [], '^', color=colors[i], markersize=16, 
                         markeredgecolor='black', markeredgewidth=2, 
                         label=f'æ— äººæœº{i+1}' if i < 3 else "")
        drone_dots.append(drone)
        
        # é€Ÿåº¦ç®­å¤´
        arrow = ax1.annotate('', xy=(0, 0), xytext=(0, 0),
                           arrowprops=dict(arrowstyle='->', color=colors[i], 
                                         lw=2, alpha=0.7))
        velocity_arrows.append(arrow)
    
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # è¿åŠ¨å¼ºåº¦å›¾
    ax2.set_title('ğŸƒ è¿åŠ¨å¼ºåº¦ç›‘æ§')
    ax2.set_xlabel('æ—¶é—´æ­¥')
    ax2.set_ylabel('è¿åŠ¨è·ç¦»')
    ax2.grid(True, alpha=0.3)
    
    # ç¼–é˜Ÿåä½œå›¾
    ax3.set_title('ğŸ¤ ç¼–é˜Ÿåä½œçŠ¶æ€')
    ax3.set_xlabel('æ—¶é—´æ­¥')
    ax3.set_ylabel('åä½œå¾—åˆ†')
    ax3.set_ylim(0, 1)
    ax3.grid(True, alpha=0.3)
    
    # ä»»åŠ¡è¿›åº¦å›¾
    ax4.set_title('ğŸ¯ ä»»åŠ¡å®Œæˆè¿›åº¦')
    ax4.set_xlabel('æ—¶é—´æ­¥')
    ax4.set_ylabel('å¹³å‡ç›®æ ‡è·ç¦»')
    ax4.grid(True, alpha=0.3)
    
    def animate(frame):
        if frame >= num_steps:
            return trail_lines + drone_dots
        
        current_positions = positions_history[frame]
        current_velocities = trajectory_data['velocities'][frame] if frame < len(trajectory_data['velocities']) else np.zeros_like(current_positions)
        
        # æ›´æ–°æ— äººæœºã€è½¨è¿¹å’Œé€Ÿåº¦ç®­å¤´
        for i, (line, drone, arrow) in enumerate(zip(trail_lines, drone_dots, velocity_arrows)):
            if i < len(current_positions):
                # è½¨è¿¹
                trail_x = [pos[i, 0] for pos in positions_history[:frame+1]]
                trail_y = [pos[i, 1] for pos in positions_history[:frame+1]]
                line.set_data(trail_x, trail_y)
                
                # æ— äººæœºä½ç½®
                drone.set_data([current_positions[i, 0]], [current_positions[i, 1]])
                
                # é€Ÿåº¦ç®­å¤´
                vel_scale = 0.5
                if frame < len(trajectory_data['velocities']):
                    vel = current_velocities[i] * vel_scale
                    arrow.set_position((current_positions[i, 0], current_positions[i, 1]))
                    arrow.xy = (current_positions[i, 0] + vel[0], 
                              current_positions[i, 1] + vel[1])
        
        # æ›´æ–°ç›‘æ§å›¾è¡¨
        if frame > 0:
            steps = list(range(frame+1))
            
            # è¿åŠ¨å¼ºåº¦
            if len(trajectory_data['step_movements']) > frame:
                avg_movements = [np.mean(movements) for movements in trajectory_data['step_movements'][:frame+1]]
                ax2.clear()
                ax2.plot(steps, avg_movements, 'orange', linewidth=3, label='å¹³å‡è¿åŠ¨è·ç¦»')
                ax2.fill_between(steps, avg_movements, alpha=0.3, color='orange')
                ax2.set_title(f'ğŸƒ è¿åŠ¨å¼ºåº¦ (æ­¥æ•°: {frame})')
                ax2.set_xlabel('æ—¶é—´æ­¥')
                ax2.set_ylabel('è¿åŠ¨è·ç¦»')
                ax2.legend()
                ax2.grid(True, alpha=0.3)
            
            # ç¼–é˜Ÿåä½œ
            if len(trajectory_data['collaboration_scores']) > frame:
                collab_scores = trajectory_data['collaboration_scores'][:frame+1]
                ax3.clear()
                ax3.plot(steps, collab_scores, 'purple', linewidth=3, label='åä½œå¾—åˆ†')
                ax3.fill_between(steps, collab_scores, alpha=0.3, color='purple')
                ax3.set_title(f'ğŸ¤ ç¼–é˜Ÿåä½œ (æ­¥æ•°: {frame})')
                ax3.set_xlabel('æ—¶é—´æ­¥')
                ax3.set_ylabel('åä½œå¾—åˆ†')
                ax3.set_ylim(0, 1)
                ax3.legend()
                ax3.grid(True, alpha=0.3)
            
            # ä»»åŠ¡è¿›åº¦
            if len(trajectory_data['goal_distances']) > frame:
                avg_goal_dists = [np.mean(dists) for dists in trajectory_data['goal_distances'][:frame+1]]
                ax4.clear()
                ax4.plot(steps, avg_goal_dists, 'green', linewidth=3, label='å¹³å‡ç›®æ ‡è·ç¦»')
                ax4.fill_between(steps, avg_goal_dists, alpha=0.3, color='green')
                ax4.set_title(f'ğŸ¯ ä»»åŠ¡è¿›åº¦ (æ­¥æ•°: {frame})')
                ax4.set_xlabel('æ—¶é—´æ­¥')
                ax4.set_ylabel('å¹³å‡ç›®æ ‡è·ç¦»')
                ax4.legend()
                ax4.grid(True, alpha=0.3)
        
        return trail_lines + drone_dots
    
    # åˆ›å»ºåŠ¨ç”»
    anim = FuncAnimation(fig, animate, frames=num_steps, 
                        interval=120, blit=False, repeat=True)
    
    # ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"DYNAMIC_COLLABORATION_{timestamp}.gif"
    
    try:
        print(f"ğŸ’¾ ä¿å­˜åŠ¨æ€å¯è§†åŒ–...")
        anim.save(output_path, writer='pillow', fps=8, dpi=130)
        print(f"âœ… ä¿å­˜æˆåŠŸ: {output_path}")
        
        # è®¡ç®—æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
        
        # è¿åŠ¨åˆ†æ
        if trajectory_data['step_movements']:
            total_movements = [sum(movements) for movements in zip(*trajectory_data['step_movements'])]
            avg_total_movement = np.mean(total_movements)
            max_movement = max([max(movements) for movements in trajectory_data['step_movements']])
            
            print(f"ğŸ“Š è¿åŠ¨éªŒè¯:")
            print(f"   å¹³å‡æ€»è¿åŠ¨: {avg_total_movement:.3f}")
            print(f"   æœ€å¤§å•æ­¥è¿åŠ¨: {max_movement:.3f}")
            print(f"   åŠ¨æ€çŠ¶æ€: {'âœ… åŠ¨æ€è¿åŠ¨' if avg_total_movement > 0.5 else 'âŒ é™æ€'}")
            print(f"   æ–‡ä»¶è´¨é‡: {'âœ… æ­£å¸¸å¤§å°' if file_size > 1.0 else 'âš ï¸ å¯èƒ½é™æ€'}")
        
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜å¤±è´¥: {e}")
        # ä¿å­˜é™æ€å›¾
        static_path = f"DYNAMIC_STATIC_{timestamp}.png"
        plt.tight_layout()
        plt.savefig(static_path, dpi=150, bbox_inches='tight')
        print(f"âœ… é™æ€å›¾ä¿å­˜: {static_path}")
        output_path = static_path
    
    plt.close()
    return output_path

if __name__ == "__main__":
    print("ğŸš€ åŠ¨æ€åä½œä¿®å¤ç³»ç»Ÿ")
    print("è§£å†³é™æ€é—®é¢˜ï¼Œç¡®ä¿æ™ºèƒ½ä½“æœ‰æ˜æ˜¾è¿åŠ¨")
    print("å¹³è¡¡åŠ¨æ€æ€§å’Œè¾¹ç•Œæ§åˆ¶")
    print("=" * 70)
    
    success = create_dynamic_collaboration()
    
    if success:
        print(f"\nğŸ‰ åŠ¨æ€åä½œä¿®å¤æˆåŠŸ!")
        print(f"ğŸš ç”Ÿæˆäº†çœŸæ­£åŠ¨æ€çš„æ— äººæœºç¼–é˜Ÿåä½œå¯è§†åŒ–")
        print(f"ğŸƒ æ™ºèƒ½ä½“ç°åœ¨æœ‰æ˜æ˜¾çš„è¿åŠ¨")
        print(f"ğŸ“ æ£€æŸ¥æ–°çš„åŠ¨æ€GIFæ–‡ä»¶")
    else:
        print(f"\nâŒ ä¿®å¤å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
 
 
 
 