#!/usr/bin/env python3
"""
äº¤äº’å¼èª²ç¨‹å­¸ç¿’å¯¦é©—
"""

import os
import subprocess
import time
from datetime import datetime

def run_interactive_experiment():
    """é‹è¡Œå¯è§€å¯Ÿçš„äº¤äº’å¼å¯¦é©—"""
    print("ğŸ¯ äº¤äº’å¼èª²ç¨‹å­¸ç¿’å¯¦é©—")
    print("=" * 60)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_log_dir = f"logs/interactive_curriculum_{timestamp}"
    
    # Phase 1: é è¨“ç·´
    print("\nğŸ“š éšæ®µ1: é è¨“ç·´ï¼ˆå¯è§€å¯Ÿè¼¸å‡ºï¼‰")
    print("-" * 50)
    
    pretrain_log_dir = os.path.join(base_log_dir, "pretrain")
    
    cmd1 = f"python train_bptt.py --config config/simple_collaboration_pretrain.yaml --device cpu --log_dir {pretrain_log_dir} --seed 42"
    
    print(f"ğŸ“ åŸ·è¡Œå‘½ä»¤: {cmd1}")
    print("ğŸ”„ é–‹å§‹é è¨“ç·´... (å¯¦æ™‚è¼¸å‡º)")
    print("-" * 30)
    
    try:
        # å¯¦æ™‚è¼¸å‡ºï¼Œä¸æ•ç²ï¼Œé™åˆ¶æ™‚é–“
        process = subprocess.Popen(cmd1, shell=True)
        
        # ç­‰å¾…120ç§’æˆ–å®Œæˆ
        try:
            process.wait(timeout=120)
            if process.returncode == 0:
                print("\nâœ… é è¨“ç·´éšæ®µå®Œæˆ")
            else:
                print(f"\nâŒ é è¨“ç·´å¤±æ•—ï¼Œè¿”å›ç¢¼: {process.returncode}")
                return False
        except subprocess.TimeoutExpired:
            print("\nâ° é è¨“ç·´2åˆ†é˜æ¸¬è©¦å®Œæˆ")
            process.terminate()
            time.sleep(2)
            if process.poll() is None:
                process.kill()
    
    except Exception as e:
        print(f"\nâŒ é è¨“ç·´ç•°å¸¸: {e}")
        return False
    
    # æª¢æŸ¥é è¨“ç·´çµæœ
    print("\nğŸ” æª¢æŸ¥é è¨“ç·´çµæœ...")
    models_dir = os.path.join(pretrain_log_dir, "models")
    
    if os.path.exists(models_dir) and os.listdir(models_dir):
        model_steps = [d for d in os.listdir(models_dir) if d.isdigit()]
        model_steps.sort(key=int)
        print(f"âœ… é è¨“ç·´æ¨¡å‹å·²ç”Ÿæˆ: {model_steps}")
        
        # Phase 2: Fine-tuning
        print(f"\nğŸ“ éšæ®µ2: Fine-tuningï¼ˆåŠ è¼‰å¾ {model_steps[-1]} æ­¥ï¼‰")
        print("-" * 50)
        
        finetune_log_dir = os.path.join(base_log_dir, "finetune")
        
        cmd2 = f"python train_bptt.py --config config/simple_collaboration.yaml --device cpu --log_dir {finetune_log_dir} --load_pretrained_model_from {pretrain_log_dir} --seed 42"
        
        print(f"ğŸ“ åŸ·è¡Œå‘½ä»¤: {cmd2}")
        print("ğŸ”„ é–‹å§‹Fine-tuning... (å¯¦æ™‚è¼¸å‡º)")
        print("-" * 30)
        
        try:
            # Fine-tuningéšæ®µï¼Œä¹Ÿé™åˆ¶æ™‚é–“
            process = subprocess.Popen(cmd2, shell=True)
            
            try:
                process.wait(timeout=120)
                if process.returncode == 0:
                    print("\nâœ… Fine-tuningéšæ®µå®Œæˆ")
                else:
                    print(f"\nâŒ Fine-tuningå¤±æ•—ï¼Œè¿”å›ç¢¼: {process.returncode}")
            except subprocess.TimeoutExpired:
                print("\nâ° Fine-tuning2åˆ†é˜æ¸¬è©¦å®Œæˆ")
                process.terminate()
                time.sleep(2)
                if process.poll() is None:
                    process.kill()
                    
        except Exception as e:
            print(f"\nâŒ Fine-tuningç•°å¸¸: {e}")
    
    else:
        print("âŒ é è¨“ç·´æ¨¡å‹æœªç”Ÿæˆï¼Œè·³éFine-tuning")
    
    # å¯¦é©—ç¸½çµ
    print(f"\nğŸ å¯¦é©—ç¸½çµ")
    print("=" * 60)
    print(f"ğŸ“ å¯¦é©—ç›®éŒ„: {base_log_dir}")
    
    # æª¢æŸ¥æ‰€æœ‰ç”Ÿæˆçš„æ¨¡å‹
    all_models = []
    for phase in ["pretrain", "finetune"]:
        phase_dir = os.path.join(base_log_dir, phase, "models")
        if os.path.exists(phase_dir):
            phase_models = [d for d in os.listdir(phase_dir) if d.isdigit()]
            if phase_models:
                phase_models.sort(key=int)
                all_models.extend([f"{phase}/{m}" for m in phase_models])
    
    if all_models:
        print(f"âœ… ç”Ÿæˆçš„æ¨¡å‹: {all_models}")
        print("ğŸ‰ èª²ç¨‹å­¸ç¿’å¯¦é©—æˆåŠŸï¼")
        
        # å»ºè­°ä¸‹ä¸€æ­¥
        print(f"\nğŸš€ ä¸‹ä¸€æ­¥å»ºè­°:")
        print(f"   python unified_visualize_bptt.py {os.path.join(base_log_dir, 'finetune')}")
        print(f"   python check_experiment_status.py")
        
        return True
    else:
        print("âŒ æ²’æœ‰ç”Ÿæˆæ¨¡å‹")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ å•Ÿå‹•äº¤äº’å¼èª²ç¨‹å­¸ç¿’å¯¦é©—")
    print("é€™å€‹å¯¦é©—æœƒé¡¯ç¤ºå¯¦æ™‚è¼¸å‡ºï¼Œæ›´å®¹æ˜“è§€å¯Ÿé€²åº¦")
    print()
    
    success = run_interactive_experiment()
    
    if success:
        print("\nğŸ‰ å¯¦é©—æˆåŠŸå®Œæˆï¼")
    else:
        print("\nğŸ’¡ æç¤º: å³ä½¿æ™‚é–“é™åˆ¶ï¼Œéƒ¨åˆ†æ¨¡å‹å¯èƒ½å·²ç”Ÿæˆ")
        print("   å¯ä»¥æª¢æŸ¥å¯¦é©—ç›®éŒ„æŸ¥çœ‹çµæœ")

if __name__ == "__main__":
    main()
 
"""
äº¤äº’å¼èª²ç¨‹å­¸ç¿’å¯¦é©—
"""

import os
import subprocess
import time
from datetime import datetime

def run_interactive_experiment():
    """é‹è¡Œå¯è§€å¯Ÿçš„äº¤äº’å¼å¯¦é©—"""
    print("ğŸ¯ äº¤äº’å¼èª²ç¨‹å­¸ç¿’å¯¦é©—")
    print("=" * 60)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_log_dir = f"logs/interactive_curriculum_{timestamp}"
    
    # Phase 1: é è¨“ç·´
    print("\nğŸ“š éšæ®µ1: é è¨“ç·´ï¼ˆå¯è§€å¯Ÿè¼¸å‡ºï¼‰")
    print("-" * 50)
    
    pretrain_log_dir = os.path.join(base_log_dir, "pretrain")
    
    cmd1 = f"python train_bptt.py --config config/simple_collaboration_pretrain.yaml --device cpu --log_dir {pretrain_log_dir} --seed 42"
    
    print(f"ğŸ“ åŸ·è¡Œå‘½ä»¤: {cmd1}")
    print("ğŸ”„ é–‹å§‹é è¨“ç·´... (å¯¦æ™‚è¼¸å‡º)")
    print("-" * 30)
    
    try:
        # å¯¦æ™‚è¼¸å‡ºï¼Œä¸æ•ç²ï¼Œé™åˆ¶æ™‚é–“
        process = subprocess.Popen(cmd1, shell=True)
        
        # ç­‰å¾…120ç§’æˆ–å®Œæˆ
        try:
            process.wait(timeout=120)
            if process.returncode == 0:
                print("\nâœ… é è¨“ç·´éšæ®µå®Œæˆ")
            else:
                print(f"\nâŒ é è¨“ç·´å¤±æ•—ï¼Œè¿”å›ç¢¼: {process.returncode}")
                return False
        except subprocess.TimeoutExpired:
            print("\nâ° é è¨“ç·´2åˆ†é˜æ¸¬è©¦å®Œæˆ")
            process.terminate()
            time.sleep(2)
            if process.poll() is None:
                process.kill()
    
    except Exception as e:
        print(f"\nâŒ é è¨“ç·´ç•°å¸¸: {e}")
        return False
    
    # æª¢æŸ¥é è¨“ç·´çµæœ
    print("\nğŸ” æª¢æŸ¥é è¨“ç·´çµæœ...")
    models_dir = os.path.join(pretrain_log_dir, "models")
    
    if os.path.exists(models_dir) and os.listdir(models_dir):
        model_steps = [d for d in os.listdir(models_dir) if d.isdigit()]
        model_steps.sort(key=int)
        print(f"âœ… é è¨“ç·´æ¨¡å‹å·²ç”Ÿæˆ: {model_steps}")
        
        # Phase 2: Fine-tuning
        print(f"\nğŸ“ éšæ®µ2: Fine-tuningï¼ˆåŠ è¼‰å¾ {model_steps[-1]} æ­¥ï¼‰")
        print("-" * 50)
        
        finetune_log_dir = os.path.join(base_log_dir, "finetune")
        
        cmd2 = f"python train_bptt.py --config config/simple_collaboration.yaml --device cpu --log_dir {finetune_log_dir} --load_pretrained_model_from {pretrain_log_dir} --seed 42"
        
        print(f"ğŸ“ åŸ·è¡Œå‘½ä»¤: {cmd2}")
        print("ğŸ”„ é–‹å§‹Fine-tuning... (å¯¦æ™‚è¼¸å‡º)")
        print("-" * 30)
        
        try:
            # Fine-tuningéšæ®µï¼Œä¹Ÿé™åˆ¶æ™‚é–“
            process = subprocess.Popen(cmd2, shell=True)
            
            try:
                process.wait(timeout=120)
                if process.returncode == 0:
                    print("\nâœ… Fine-tuningéšæ®µå®Œæˆ")
                else:
                    print(f"\nâŒ Fine-tuningå¤±æ•—ï¼Œè¿”å›ç¢¼: {process.returncode}")
            except subprocess.TimeoutExpired:
                print("\nâ° Fine-tuning2åˆ†é˜æ¸¬è©¦å®Œæˆ")
                process.terminate()
                time.sleep(2)
                if process.poll() is None:
                    process.kill()
                    
        except Exception as e:
            print(f"\nâŒ Fine-tuningç•°å¸¸: {e}")
    
    else:
        print("âŒ é è¨“ç·´æ¨¡å‹æœªç”Ÿæˆï¼Œè·³éFine-tuning")
    
    # å¯¦é©—ç¸½çµ
    print(f"\nğŸ å¯¦é©—ç¸½çµ")
    print("=" * 60)
    print(f"ğŸ“ å¯¦é©—ç›®éŒ„: {base_log_dir}")
    
    # æª¢æŸ¥æ‰€æœ‰ç”Ÿæˆçš„æ¨¡å‹
    all_models = []
    for phase in ["pretrain", "finetune"]:
        phase_dir = os.path.join(base_log_dir, phase, "models")
        if os.path.exists(phase_dir):
            phase_models = [d for d in os.listdir(phase_dir) if d.isdigit()]
            if phase_models:
                phase_models.sort(key=int)
                all_models.extend([f"{phase}/{m}" for m in phase_models])
    
    if all_models:
        print(f"âœ… ç”Ÿæˆçš„æ¨¡å‹: {all_models}")
        print("ğŸ‰ èª²ç¨‹å­¸ç¿’å¯¦é©—æˆåŠŸï¼")
        
        # å»ºè­°ä¸‹ä¸€æ­¥
        print(f"\nğŸš€ ä¸‹ä¸€æ­¥å»ºè­°:")
        print(f"   python unified_visualize_bptt.py {os.path.join(base_log_dir, 'finetune')}")
        print(f"   python check_experiment_status.py")
        
        return True
    else:
        print("âŒ æ²’æœ‰ç”Ÿæˆæ¨¡å‹")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ å•Ÿå‹•äº¤äº’å¼èª²ç¨‹å­¸ç¿’å¯¦é©—")
    print("é€™å€‹å¯¦é©—æœƒé¡¯ç¤ºå¯¦æ™‚è¼¸å‡ºï¼Œæ›´å®¹æ˜“è§€å¯Ÿé€²åº¦")
    print()
    
    success = run_interactive_experiment()
    
    if success:
        print("\nğŸ‰ å¯¦é©—æˆåŠŸå®Œæˆï¼")
    else:
        print("\nğŸ’¡ æç¤º: å³ä½¿æ™‚é–“é™åˆ¶ï¼Œéƒ¨åˆ†æ¨¡å‹å¯èƒ½å·²ç”Ÿæˆ")
        print("   å¯ä»¥æª¢æŸ¥å¯¦é©—ç›®éŒ„æŸ¥çœ‹çµæœ")

if __name__ == "__main__":
    main()
 
 
 
 