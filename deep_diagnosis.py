#!/usr/bin/env python3
"""
æ·±å…¥è¨ºæ–·æ¸¬è©¦ - é‡ç¾è¨“ç·´å•é¡Œ
"""

import torch
import yaml
import os
import traceback

def test_training_pipeline():
    """æ¸¬è©¦å®Œæ•´çš„è¨“ç·´æµç¨‹"""
    print("ğŸ”¬ æ·±å…¥è¨ºæ–· - æ¸¬è©¦è¨“ç·´æµç¨‹")
    print("=" * 50)
    
    try:
        # 1. åŠ è¼‰é…ç½®
        print("1ï¸âƒ£ åŠ è¼‰é…ç½®...")
        with open('config/simple_collaboration_pretrain.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print("   âœ… é…ç½®åŠ è¼‰æˆåŠŸ")
        
        # 2. å‰µå»ºç’°å¢ƒ
        print("\n2ï¸âƒ£ å‰µå»ºç’°å¢ƒ...")
        from gcbfplus.env import DoubleIntegratorEnv
        env = DoubleIntegratorEnv(config['env'])
        env = env.to('cpu')
        print(f"   âœ… ç’°å¢ƒå‰µå»ºæˆåŠŸ: {env.observation_shape}")
        
        # 3. æ¸¬è©¦ç’°å¢ƒé‡ç½®å’Œè§€æ¸¬
        print("\n3ï¸âƒ£ æ¸¬è©¦ç’°å¢ƒé‡ç½®...")
        state = env.reset()
        obs = env.get_observation(state)
        print(f"   ğŸ“Š è§€æ¸¬å½¢ç‹€: {obs.shape}")
        print(f"   ğŸ“Š è§€æ¸¬å…§å®¹ç¤ºä¾‹: {obs[0, :3]}")  # ç¬¬ä¸€å€‹æ™ºèƒ½é«”çš„å‰3ç¶­
        
        # 4. å‰µå»ºç­–ç•¥ç¶²çµ¡
        print("\n4ï¸âƒ£ å‰µå»ºç­–ç•¥ç¶²çµ¡...")
        from gcbfplus.policy import create_policy_from_config
        policy_config = config['networks']['policy']
        
        print(f"   ğŸ“‹ ç­–ç•¥é…ç½®æª¢æŸ¥:")
        print(f"     - è¼¸å…¥ç¶­åº¦: {policy_config['perception']['input_dim']}")
        print(f"     - éš±è—ç¶­åº¦: {policy_config['perception']['hidden_dim']}")
        print(f"     - è¼¸å‡ºç¶­åº¦: {policy_config['policy_head']['output_dim']}")
        
        policy = create_policy_from_config(policy_config)
        print("   âœ… ç­–ç•¥ç¶²çµ¡å‰µå»ºæˆåŠŸ")
        
        # 5. æ¸¬è©¦å‰å‘å‚³æ’­
        print("\n5ï¸âƒ£ æ¸¬è©¦å‰å‘å‚³æ’­...")
        batch_obs = obs.unsqueeze(0)  # [1, 6, 9]
        print(f"   ğŸ“Š æ‰¹é‡è§€æ¸¬å½¢ç‹€: {batch_obs.shape}")
        
        with torch.no_grad():
            actions, alpha = policy(batch_obs)
            print(f"   ğŸ“Š å‹•ä½œè¼¸å‡º: {actions.shape}")
            print(f"   ğŸ“Š Alphaè¼¸å‡º: {alpha.shape}")
            print(f"   ğŸ“Š å‹•ä½œå€¼ç¤ºä¾‹: {actions[0, 0]}")  # ç¬¬ä¸€å€‹æ™ºèƒ½é«”çš„å‹•ä½œ
        
        print("   âœ… å‰å‘å‚³æ’­æ¸¬è©¦æˆåŠŸ")
        
        # 6. å‰µå»ºè¨“ç·´å™¨ï¼ˆç°¡åŒ–é…ç½®ï¼‰
        print("\n6ï¸âƒ£ å‰µå»ºè¨“ç·´å™¨...")
        from gcbfplus.trainer.bptt_trainer import BPTTTrainer
        
        # æœ€å°åŒ–è¨“ç·´é…ç½®
        training_config = {
            'horizon_length': 5,  # å¾ˆçŸ­çš„æ™‚é–“ç¯„åœ
            'learning_rate': 0.01,
            'training_steps': 2,  # åªè¨“ç·´2æ­¥
            'batch_size': 2,      # å°æ‰¹é‡
            'device': 'cpu',
            'log_interval': 1,
            'save_interval': 1,
            'cbf_alpha': 1.0,
            'goal_weight': 1.0,
            'safety_weight': 1.0,
            'control_weight': 0.1,
            'jerk_weight': 0.01,
            'alpha_reg_weight': 0.01,
            'progress_weight': 0.1
        }
        
        print(f"   ğŸ“‹ è¨“ç·´é…ç½®: {training_config}")
        
        trainer = BPTTTrainer(
            env=env,
            policy_network=policy,
            cbf_network=None,  # ä¸ä½¿ç”¨CBFä»¥ç°¡åŒ–
            config=training_config
        )
        
        # è¨­ç½®ä¿å­˜ç›®éŒ„
        log_dir = "logs/deep_diagnosis"
        os.makedirs(log_dir, exist_ok=True)
        trainer.log_dir = log_dir
        trainer.model_dir = os.path.join(log_dir, 'models')
        os.makedirs(trainer.model_dir, exist_ok=True)
        
        print("   âœ… è¨“ç·´å™¨å‰µå»ºæˆåŠŸ")
        
        # 7. å˜—è©¦å–®æ­¥è¨“ç·´
        print("\n7ï¸âƒ£ åŸ·è¡Œå¾®å‹è¨“ç·´...")
        print("   ğŸ”„ é–‹å§‹2æ­¥è¨“ç·´...")
        
        try:
            trainer.train()
            print("   âœ… è¨“ç·´å®Œæˆï¼")
            
            # æª¢æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
            if os.path.exists(trainer.model_dir):
                files = os.listdir(trainer.model_dir)
                if files:
                    print(f"   ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶: {files}")
                    return True, "è¨“ç·´æˆåŠŸ"
                else:
                    return False, "è¨“ç·´å®Œæˆä½†æœªç”Ÿæˆæ–‡ä»¶"
            else:
                return False, "æ¨¡å‹ç›®éŒ„æœªå‰µå»º"
                
        except Exception as train_error:
            print(f"   âŒ è¨“ç·´å¤±æ•—: {train_error}")
            traceback.print_exc()
            return False, f"è¨“ç·´éŒ¯èª¤: {train_error}"
            
    except Exception as e:
        print(f"âŒ æµç¨‹æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False, f"æµç¨‹éŒ¯èª¤: {e}"

def main():
    """ä¸»è¨ºæ–·å‡½æ•¸"""
    print("ğŸš€ æ·±å…¥è¨ºæ–·é–‹å§‹")
    print("ç›®æ¨™: æ‰¾å‡ºè¨“ç·´ç„¡æ³•ç”Ÿæˆæ¨¡å‹çš„ç¢ºåˆ‡åŸå› ")
    print()
    
    success, message = test_training_pipeline()
    
    print("\n" + "=" * 50)
    if success:
        print("ğŸ‰ è¨ºæ–·çµæœ: æˆåŠŸï¼")
        print("âœ… è¨“ç·´æµç¨‹æ­£å¸¸å·¥ä½œ")
        print("ğŸ’¡ ä¹‹å‰çš„å¯¦é©—å¤±æ•—å¯èƒ½æ˜¯å› ç‚º:")
        print("   1. è¨“ç·´æ­¥æ•¸è¨­ç½®éå¤šï¼Œæ™‚é–“å¤ªé•·")
        print("   2. é€²ç¨‹è¢«ç”¨æˆ¶ä¸­æ–·")
        print("   3. ç³»çµ±è³‡æºå•é¡Œ")
        print("\nğŸš€ å»ºè­°: å¯ä»¥é‹è¡Œå®Œæ•´å¯¦é©—ï¼Œç¢ºä¿æœ‰è¶³å¤ æ™‚é–“")
    else:
        print("âŒ è¨ºæ–·çµæœ: ç™¼ç¾å•é¡Œï¼")
        print(f"ğŸ” å•é¡Œè©³æƒ…: {message}")
        print("ğŸ’¡ éœ€è¦ä¿®å¾©æ­¤å•é¡Œæ‰èƒ½ç¹¼çºŒ")
    
    print(f"\nğŸ“Š è¨ºæ–·è©³æƒ…: {message}")

if __name__ == "__main__":
    main()
 
"""
æ·±å…¥è¨ºæ–·æ¸¬è©¦ - é‡ç¾è¨“ç·´å•é¡Œ
"""

import torch
import yaml
import os
import traceback

def test_training_pipeline():
    """æ¸¬è©¦å®Œæ•´çš„è¨“ç·´æµç¨‹"""
    print("ğŸ”¬ æ·±å…¥è¨ºæ–· - æ¸¬è©¦è¨“ç·´æµç¨‹")
    print("=" * 50)
    
    try:
        # 1. åŠ è¼‰é…ç½®
        print("1ï¸âƒ£ åŠ è¼‰é…ç½®...")
        with open('config/simple_collaboration_pretrain.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print("   âœ… é…ç½®åŠ è¼‰æˆåŠŸ")
        
        # 2. å‰µå»ºç’°å¢ƒ
        print("\n2ï¸âƒ£ å‰µå»ºç’°å¢ƒ...")
        from gcbfplus.env import DoubleIntegratorEnv
        env = DoubleIntegratorEnv(config['env'])
        env = env.to('cpu')
        print(f"   âœ… ç’°å¢ƒå‰µå»ºæˆåŠŸ: {env.observation_shape}")
        
        # 3. æ¸¬è©¦ç’°å¢ƒé‡ç½®å’Œè§€æ¸¬
        print("\n3ï¸âƒ£ æ¸¬è©¦ç’°å¢ƒé‡ç½®...")
        state = env.reset()
        obs = env.get_observation(state)
        print(f"   ğŸ“Š è§€æ¸¬å½¢ç‹€: {obs.shape}")
        print(f"   ğŸ“Š è§€æ¸¬å…§å®¹ç¤ºä¾‹: {obs[0, :3]}")  # ç¬¬ä¸€å€‹æ™ºèƒ½é«”çš„å‰3ç¶­
        
        # 4. å‰µå»ºç­–ç•¥ç¶²çµ¡
        print("\n4ï¸âƒ£ å‰µå»ºç­–ç•¥ç¶²çµ¡...")
        from gcbfplus.policy import create_policy_from_config
        policy_config = config['networks']['policy']
        
        print(f"   ğŸ“‹ ç­–ç•¥é…ç½®æª¢æŸ¥:")
        print(f"     - è¼¸å…¥ç¶­åº¦: {policy_config['perception']['input_dim']}")
        print(f"     - éš±è—ç¶­åº¦: {policy_config['perception']['hidden_dim']}")
        print(f"     - è¼¸å‡ºç¶­åº¦: {policy_config['policy_head']['output_dim']}")
        
        policy = create_policy_from_config(policy_config)
        print("   âœ… ç­–ç•¥ç¶²çµ¡å‰µå»ºæˆåŠŸ")
        
        # 5. æ¸¬è©¦å‰å‘å‚³æ’­
        print("\n5ï¸âƒ£ æ¸¬è©¦å‰å‘å‚³æ’­...")
        batch_obs = obs.unsqueeze(0)  # [1, 6, 9]
        print(f"   ğŸ“Š æ‰¹é‡è§€æ¸¬å½¢ç‹€: {batch_obs.shape}")
        
        with torch.no_grad():
            actions, alpha = policy(batch_obs)
            print(f"   ğŸ“Š å‹•ä½œè¼¸å‡º: {actions.shape}")
            print(f"   ğŸ“Š Alphaè¼¸å‡º: {alpha.shape}")
            print(f"   ğŸ“Š å‹•ä½œå€¼ç¤ºä¾‹: {actions[0, 0]}")  # ç¬¬ä¸€å€‹æ™ºèƒ½é«”çš„å‹•ä½œ
        
        print("   âœ… å‰å‘å‚³æ’­æ¸¬è©¦æˆåŠŸ")
        
        # 6. å‰µå»ºè¨“ç·´å™¨ï¼ˆç°¡åŒ–é…ç½®ï¼‰
        print("\n6ï¸âƒ£ å‰µå»ºè¨“ç·´å™¨...")
        from gcbfplus.trainer.bptt_trainer import BPTTTrainer
        
        # æœ€å°åŒ–è¨“ç·´é…ç½®
        training_config = {
            'horizon_length': 5,  # å¾ˆçŸ­çš„æ™‚é–“ç¯„åœ
            'learning_rate': 0.01,
            'training_steps': 2,  # åªè¨“ç·´2æ­¥
            'batch_size': 2,      # å°æ‰¹é‡
            'device': 'cpu',
            'log_interval': 1,
            'save_interval': 1,
            'cbf_alpha': 1.0,
            'goal_weight': 1.0,
            'safety_weight': 1.0,
            'control_weight': 0.1,
            'jerk_weight': 0.01,
            'alpha_reg_weight': 0.01,
            'progress_weight': 0.1
        }
        
        print(f"   ğŸ“‹ è¨“ç·´é…ç½®: {training_config}")
        
        trainer = BPTTTrainer(
            env=env,
            policy_network=policy,
            cbf_network=None,  # ä¸ä½¿ç”¨CBFä»¥ç°¡åŒ–
            config=training_config
        )
        
        # è¨­ç½®ä¿å­˜ç›®éŒ„
        log_dir = "logs/deep_diagnosis"
        os.makedirs(log_dir, exist_ok=True)
        trainer.log_dir = log_dir
        trainer.model_dir = os.path.join(log_dir, 'models')
        os.makedirs(trainer.model_dir, exist_ok=True)
        
        print("   âœ… è¨“ç·´å™¨å‰µå»ºæˆåŠŸ")
        
        # 7. å˜—è©¦å–®æ­¥è¨“ç·´
        print("\n7ï¸âƒ£ åŸ·è¡Œå¾®å‹è¨“ç·´...")
        print("   ğŸ”„ é–‹å§‹2æ­¥è¨“ç·´...")
        
        try:
            trainer.train()
            print("   âœ… è¨“ç·´å®Œæˆï¼")
            
            # æª¢æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
            if os.path.exists(trainer.model_dir):
                files = os.listdir(trainer.model_dir)
                if files:
                    print(f"   ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶: {files}")
                    return True, "è¨“ç·´æˆåŠŸ"
                else:
                    return False, "è¨“ç·´å®Œæˆä½†æœªç”Ÿæˆæ–‡ä»¶"
            else:
                return False, "æ¨¡å‹ç›®éŒ„æœªå‰µå»º"
                
        except Exception as train_error:
            print(f"   âŒ è¨“ç·´å¤±æ•—: {train_error}")
            traceback.print_exc()
            return False, f"è¨“ç·´éŒ¯èª¤: {train_error}"
            
    except Exception as e:
        print(f"âŒ æµç¨‹æ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False, f"æµç¨‹éŒ¯èª¤: {e}"

def main():
    """ä¸»è¨ºæ–·å‡½æ•¸"""
    print("ğŸš€ æ·±å…¥è¨ºæ–·é–‹å§‹")
    print("ç›®æ¨™: æ‰¾å‡ºè¨“ç·´ç„¡æ³•ç”Ÿæˆæ¨¡å‹çš„ç¢ºåˆ‡åŸå› ")
    print()
    
    success, message = test_training_pipeline()
    
    print("\n" + "=" * 50)
    if success:
        print("ğŸ‰ è¨ºæ–·çµæœ: æˆåŠŸï¼")
        print("âœ… è¨“ç·´æµç¨‹æ­£å¸¸å·¥ä½œ")
        print("ğŸ’¡ ä¹‹å‰çš„å¯¦é©—å¤±æ•—å¯èƒ½æ˜¯å› ç‚º:")
        print("   1. è¨“ç·´æ­¥æ•¸è¨­ç½®éå¤šï¼Œæ™‚é–“å¤ªé•·")
        print("   2. é€²ç¨‹è¢«ç”¨æˆ¶ä¸­æ–·")
        print("   3. ç³»çµ±è³‡æºå•é¡Œ")
        print("\nğŸš€ å»ºè­°: å¯ä»¥é‹è¡Œå®Œæ•´å¯¦é©—ï¼Œç¢ºä¿æœ‰è¶³å¤ æ™‚é–“")
    else:
        print("âŒ è¨ºæ–·çµæœ: ç™¼ç¾å•é¡Œï¼")
        print(f"ğŸ” å•é¡Œè©³æƒ…: {message}")
        print("ğŸ’¡ éœ€è¦ä¿®å¾©æ­¤å•é¡Œæ‰èƒ½ç¹¼çºŒ")
    
    print(f"\nğŸ“Š è¨ºæ–·è©³æƒ…: {message}")

if __name__ == "__main__":
    main()
 
 
 
 