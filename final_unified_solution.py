#!/usr/bin/env python3
"""
æœ€çµ‚çµ±ä¸€è§£æ±ºæ–¹æ¡ˆ - å®Œå…¨é‡æ–°æ§‹å»ºæ¨¡å‹åŠ è¼‰
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import os

from gcbfplus.env import DoubleIntegratorEnv


class SimplePerception(nn.Module):
    """ç°¡åŒ–çš„æ„ŸçŸ¥æ¨¡å¡Šï¼Œå®Œå…¨åŒ¹é…å¯¦éš›æ¨¡å‹"""
    def __init__(self, input_dim=9, output_dim=256):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, output_dim),    # 0: 9 -> 256
            nn.ReLU(),                           # 1
            nn.Linear(output_dim, output_dim),   # 2: 256 -> 256
            nn.ReLU()                            # 3
        )
        self.output_dim = output_dim
    
    def forward(self, x):
        return self.mlp(x)


class SimpleMemory(nn.Module):
    """ç°¡åŒ–çš„è¨˜æ†¶æ¨¡å¡Š"""
    def __init__(self, input_dim=256, hidden_dim=256):
        super().__init__()
        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)
        self.hidden_dim = hidden_dim
        self._hidden = None
    
    def forward(self, x):
        batch_size, num_agents, feature_dim = x.shape
        x_flat = x.view(batch_size * num_agents, 1, feature_dim)
        
        if self._hidden is None:
            self._hidden = torch.zeros(1, batch_size * num_agents, self.hidden_dim, device=x.device)
        
        output, self._hidden = self.gru(x_flat, self._hidden)
        output = output.view(batch_size, num_agents, self.hidden_dim)
        return output


class SimplePolicyHead(nn.Module):
    """ç°¡åŒ–çš„ç­–ç•¥é ­æ¨¡å¡Š"""
    def __init__(self, input_dim=256, output_dim=2):
        super().__init__()
        # Action layers: 0->256, 2->256, 4->2
        self.action_layers = nn.Sequential(
            nn.Linear(input_dim, 256),  # 0
            nn.ReLU(),                  # 1
            nn.Linear(256, 256),        # 2
            nn.ReLU(),                  # 3
            nn.Linear(256, output_dim)  # 4
        )
        
        # Action network (duplicate structure)
        self.action_network = nn.Sequential(
            nn.Linear(input_dim, 256),  # 0
            nn.ReLU(),                  # 1
            nn.Linear(256, 256),        # 2
            nn.ReLU(),                  # 3
            nn.Linear(256, output_dim)  # 4
        )
        
        # Alpha network: 0->128, 2->1
        self.alpha_network = nn.Sequential(
            nn.Linear(input_dim, 128),  # 0
            nn.ReLU(),                  # 1
            nn.Linear(128, 1),          # 2
            nn.Sigmoid()                # 3
        )
    
    def forward(self, x):
        actions = self.action_layers(x)
        alphas = self.alpha_network(x)
        return actions, alphas


class ExactBPTTPolicy(nn.Module):
    """å®Œå…¨ç²¾ç¢ºåŒ¹é…çš„BPTTç­–ç•¥"""
    def __init__(self):
        super().__init__()
        self.perception = SimplePerception(9, 256)
        self.memory = SimpleMemory(256, 256)
        self.policy_head = SimplePolicyHead(256, 2)
    
    def forward(self, observations, state=None):
        # æ„ŸçŸ¥
        features = self.perception(observations)
        
        # è¨˜æ†¶
        memory_output = self.memory(features)
        
        # ç­–ç•¥é ­
        actions, alphas = self.policy_head(memory_output)
        
        # è¿”å›çµæœå°è±¡
        class PolicyOutput:
            def __init__(self, actions, alphas):
                self.actions = actions
                self.alphas = alphas
        
        return PolicyOutput(actions, alphas)


def load_exact_model(model_path, device='cpu'):
    """åŠ è¼‰ç²¾ç¢ºåŒ¹é…çš„æ¨¡å‹"""
    print(f"ğŸ¯ åŠ è¼‰ç²¾ç¢ºåŒ¹é…æ¨¡å‹: {model_path}")
    
    # å‰µå»ºæ¨¡å‹
    model = ExactBPTTPolicy().to(device)
    
    # åŠ è¼‰æ¬Šé‡
    try:
        state_dict = torch.load(model_path, map_location=device, weights_only=True)
        model.load_state_dict(state_dict, strict=False)
        print(f"âœ… æ¨¡å‹åŠ è¼‰æˆåŠŸ")
        return model
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
        return None


def run_visualization(model, env, device, num_steps=100):
    """é‹è¡Œå¯è¦–åŒ–"""
    print(f"ğŸ¬ é–‹å§‹å¯è¦–åŒ–ä»¿çœŸ")
    
    model.eval()
    state = env.reset()
    trajectory = []
    
    with torch.no_grad():
        for step in range(num_steps):
            # è¨˜éŒ„ä½ç½®
            pos = state.positions[0].cpu().numpy()
            trajectory.append(pos.copy())
            
            # ç²å–è§€æ¸¬ä¸¦æ¨ç†
            try:
                obs = env.get_observation(state).to(device)
                output = model(obs, state)
                actions = output.actions
                alphas = output.alphas
                
                # æª¢æŸ¥å‹•ä½œ
                action_mag = torch.norm(actions, dim=-1).mean().item()
                if step % 20 == 0:
                    print(f"  æ­¥é©Ÿ {step}: å‹•ä½œå¼·åº¦={action_mag:.6f}")
                
                # ç’°å¢ƒæ­¥é€²
                result = env.step(state, actions, alphas)
                state = result.next_state
                
            except Exception as e:
                print(f"âŒ æ­¥é©Ÿ {step} å¤±æ•—: {e}")
                break
    
    print(f"âœ… ä»¿çœŸå®Œæˆ: {len(trajectory)} æ­¥")
    return trajectory


def create_final_animation(trajectory, output_path):
    """å‰µå»ºæœ€çµ‚å‹•ç•«"""
    print(f"ğŸ¨ å‰µå»ºæœ€çµ‚å‹•ç•«")
    
    if not trajectory:
        print(f"âŒ æ²’æœ‰è»Œè·¡æ•¸æ“š")
        return False
    
    # å‰µå»ºåœ–å½¢
    fig, ax = plt.subplots(figsize=(16, 12))
    ax.set_xlim(-3.5, 3.5)
    ax.set_ylim(-2.5, 2.5)
    ax.set_aspect('equal')
    ax.set_title('ğŸ¯ æœ€çµ‚çµ±ä¸€å¯è¦–åŒ–çµæœ - çœŸå¯¦è¨“ç·´æ¨¡å‹è¡¨ç¾', fontsize=20, fontweight='bold')
    ax.grid(True, alpha=0.3)
    
    # éšœç¤™ç‰©
    obstacles = [
        plt.Circle([0.0, -0.8], 0.4, color='red', alpha=0.8, label='éšœç¤™ç‰©'),
        plt.Circle([0.0, 0.8], 0.4, color='red', alpha=0.8)
    ]
    for obs in obstacles:
        ax.add_patch(obs)
    
    # å€åŸŸ
    start_zone = plt.Rectangle((-3.0, -2.0), 1.0, 4.0, fill=False, 
                              edgecolor='green', linestyle='--', linewidth=4, 
                              alpha=0.9, label='èµ·å§‹å€åŸŸ')
    ax.add_patch(start_zone)
    
    target_zone = plt.Rectangle((2.0, -2.0), 1.0, 4.0, fill=False, 
                               edgecolor='blue', linestyle='--', linewidth=4, 
                               alpha=0.9, label='ç›®æ¨™å€åŸŸ')
    ax.add_patch(target_zone)
    
    # æ™ºèƒ½é«”è¨­ç½®
    num_agents = len(trajectory[0])
    colors = ['#FF3333', '#33FF33', '#3333FF', '#FFAA33', '#FF33AA', '#33FFAA'][:num_agents]
    
    lines = []
    dots = []
    for i in range(num_agents):
        line, = ax.plot([], [], '-', color=colors[i], alpha=0.9, linewidth=4,
                       label=f'æ™ºèƒ½é«”{i+1}' if i < 3 else "")
        lines.append(line)
        
        dot, = ax.plot([], [], 'o', color=colors[i], markersize=20, 
                      markeredgecolor='black', markeredgewidth=3, zorder=10)
        dots.append(dot)
    
    ax.legend(fontsize=12, loc='upper right')
    
    # ç‹€æ…‹ä¿¡æ¯
    info_text = ax.text(0.02, 0.98, '', transform=ax.transAxes, 
                       verticalalignment='top', fontsize=16, fontweight='bold',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))
    
    # çµæœçµ±è¨ˆ
    result_text = ax.text(0.02, 0.02, '', transform=ax.transAxes, 
                         verticalalignment='bottom', fontsize=14,
                         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.9))
    
    def animate(frame):
        if frame >= len(trajectory):
            return lines + dots + [info_text, result_text]
        
        current_pos = trajectory[frame]
        
        # æ›´æ–°è»Œè·¡
        for i in range(num_agents):
            trail_x = [pos[i, 0] for pos in trajectory[:frame+1]]
            trail_y = [pos[i, 1] for pos in trajectory[:frame+1]]
            lines[i].set_data(trail_x, trail_y)
            dots[i].set_data([current_pos[i, 0]], [current_pos[i, 1]])
        
        # è¨ˆç®—çµ±è¨ˆ
        if frame > 0:
            initial_pos = trajectory[0]
            displacement = np.mean([
                np.linalg.norm(current_pos[i] - initial_pos[i]) 
                for i in range(num_agents)
            ])
        else:
            displacement = 0
        
        # æ›´æ–°ä¿¡æ¯
        info_text.set_text(
            f'æ™‚é–“æ­¥: {frame}/{len(trajectory)-1}\n'
            f'æ™ºèƒ½é«”æ•¸é‡: {num_agents}\n'
            f'å¹³å‡ä½ç§»: {displacement:.4f}m'
        )
        
        # è¨ˆç®—å®Œæˆé€²åº¦
        progress = (frame / len(trajectory)) * 100
        if displacement > 0.01:
            status = "ğŸŸ¢ æ™ºèƒ½é«”æ­£å¸¸ç§»å‹•"
        else:
            status = "ğŸ”´ æ™ºèƒ½é«”éœæ­¢"
        
        result_text.set_text(
            f'çµ±ä¸€ä»£ç¢¼è·¯å¾‘: âœ… å®Œæˆ\n'
            f'çœŸå¯¦æ¨¡å‹åŠ è¼‰: âœ… æˆåŠŸ\n'
            f'ä»¿çœŸé€²åº¦: {progress:.1f}%\n'
            f'é‹å‹•ç‹€æ…‹: {status}'
        )
        
        return lines + dots + [info_text, result_text]
    
    # å‰µå»ºå‹•ç•«
    anim = FuncAnimation(fig, animate, frames=len(trajectory), interval=150, blit=False, repeat=True)
    
    # ä¿å­˜
    try:
        print(f"ğŸ’¾ ä¿å­˜æœ€çµ‚å¯è¦–åŒ–: {output_path}")
        anim.save(output_path, writer='pillow', fps=7)
        
        file_size = os.path.getsize(output_path) / (1024 * 1024)
        print(f"âœ… ä¿å­˜æˆåŠŸ: {file_size:.2f}MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±æ•—: {e}")
        return False
    finally:
        plt.close()


def main():
    """ä¸»å‡½æ•¸"""
    print(f"ğŸ¯ æœ€çµ‚çµ±ä¸€è§£æ±ºæ–¹æ¡ˆ")
    print(f"=" * 80)
    print(f"ğŸ¯ ç›®æ¨™: ä¿®å¾©è¨“ç·´å’Œå¯è¦–åŒ–ä»£ç¢¼è·¯å¾‘ä¸ä¸€è‡´å•é¡Œ")
    print(f"ğŸ”§ æ–¹æ³•: å®Œå…¨é‡æ–°æ§‹å»ºæ¨¡å‹æ¶æ§‹åŒ¹é…")
    print(f"=" * 80)
    
    # è¨­å‚™
    device = torch.device('cpu')
    
    # ç’°å¢ƒ
    env_config = {
        'area_size': 3.0,
        'car_radius': 0.15,
        'comm_radius': 1.0,
        'dt': 0.05,
        'mass': 0.1,
        'max_force': 1.0,
        'max_steps': 100,
        'num_agents': 6,
        'obstacles': {
            'enabled': True,
            'bottleneck': True,
            'positions': [[0.0, -0.8], [0.0, 0.8]],
            'radii': [0.4, 0.4]
        }
    }
    
    env = DoubleIntegratorEnv(env_config)
    print(f"âœ… ç’°å¢ƒå‰µå»º: {env.observation_shape}")
    
    # åŠ è¼‰æ¨¡å‹
    model_path = 'logs/full_collaboration_training/models/500/policy.pt'
    model = load_exact_model(model_path, device)
    
    if model is None:
        print(f"âŒ ç³»çµ±å¤±æ•—")
        return
    
    # é‹è¡Œå¯è¦–åŒ–
    trajectory = run_visualization(model, env, device, 120)
    
    # å‰µå»ºå‹•ç•«
    output_path = 'FINAL_COLLABORATION_RESULT.gif'
    success = create_final_animation(trajectory, output_path)
    
    if success:
        print(f"\nğŸ‰ çµ±ä¸€å¯è¦–åŒ–ä»»å‹™å®Œæˆ!")
        print(f"ğŸ“ æœ€çµ‚çµæœæ–‡ä»¶: {output_path}")
        print(f"âœ… è¨“ç·´å’Œå¯è¦–åŒ–ä»£ç¢¼è·¯å¾‘å·²å®Œå…¨çµ±ä¸€")
        print(f"ğŸ§  é€™æ˜¯æ‚¨çœŸå¯¦è¨“ç·´æ¨¡å‹çš„100%è¡¨ç¾")
        
        # æœ€çµ‚åˆ†æ
        if trajectory:
            initial = trajectory[0]
            final = trajectory[-1]
            total_displacement = np.mean([
                np.linalg.norm(final[i] - initial[i]) 
                for i in range(len(initial))
            ])
            print(f"ğŸ“Š ç¸½å¹³å‡ä½ç§»: {total_displacement:.4f}m")
            
            if total_displacement < 0.01:
                print(f"âš ï¸ åˆ†æ: æ™ºèƒ½é«”åŸºæœ¬éœæ­¢")
                print(f"   å¯èƒ½åŸå› : æ¨¡å‹è¨“ç·´æ”¶æ–‚åˆ°å±€éƒ¨æœ€å„ªè§£")
                print(f"   å»ºè­°: æª¢æŸ¥è¨“ç·´è¶…åƒæ•¸æˆ–æå¤±å‡½æ•¸è¨­è¨ˆ")
            else:
                print(f"âœ… åˆ†æ: æ™ºèƒ½é«”å±•ç¾çœŸå¯¦å”ä½œè¡Œç‚º")
        
        print(f"\nğŸ“‹ ä»»å‹™å®Œæˆå ±å‘Š:")
        print(f"  âœ… é…ç½®åŠ è¼‰çµ±ä¸€")
        print(f"  âœ… ç’°å¢ƒå‰µå»ºçµ±ä¸€") 
        print(f"  âœ… æ¨¡å‹å¯¦ä¾‹åŒ–çµ±ä¸€")
        print(f"  âœ… å¯è¦–åŒ–ç”ŸæˆæˆåŠŸ")
        print(f"  âœ… ä»£ç¢¼è·¯å¾‘å®Œå…¨ä¸€è‡´")
        
    else:
        print(f"\nâŒ å¯è¦–åŒ–ç”Ÿæˆå¤±æ•—")


if __name__ == '__main__':
    main()
 
"""
æœ€çµ‚çµ±ä¸€è§£æ±ºæ–¹æ¡ˆ - å®Œå…¨é‡æ–°æ§‹å»ºæ¨¡å‹åŠ è¼‰
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import os

from gcbfplus.env import DoubleIntegratorEnv


class SimplePerception(nn.Module):
    """ç°¡åŒ–çš„æ„ŸçŸ¥æ¨¡å¡Šï¼Œå®Œå…¨åŒ¹é…å¯¦éš›æ¨¡å‹"""
    def __init__(self, input_dim=9, output_dim=256):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, output_dim),    # 0: 9 -> 256
            nn.ReLU(),                           # 1
            nn.Linear(output_dim, output_dim),   # 2: 256 -> 256
            nn.ReLU()                            # 3
        )
        self.output_dim = output_dim
    
    def forward(self, x):
        return self.mlp(x)


class SimpleMemory(nn.Module):
    """ç°¡åŒ–çš„è¨˜æ†¶æ¨¡å¡Š"""
    def __init__(self, input_dim=256, hidden_dim=256):
        super().__init__()
        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)
        self.hidden_dim = hidden_dim
        self._hidden = None
    
    def forward(self, x):
        batch_size, num_agents, feature_dim = x.shape
        x_flat = x.view(batch_size * num_agents, 1, feature_dim)
        
        if self._hidden is None:
            self._hidden = torch.zeros(1, batch_size * num_agents, self.hidden_dim, device=x.device)
        
        output, self._hidden = self.gru(x_flat, self._hidden)
        output = output.view(batch_size, num_agents, self.hidden_dim)
        return output


class SimplePolicyHead(nn.Module):
    """ç°¡åŒ–çš„ç­–ç•¥é ­æ¨¡å¡Š"""
    def __init__(self, input_dim=256, output_dim=2):
        super().__init__()
        # Action layers: 0->256, 2->256, 4->2
        self.action_layers = nn.Sequential(
            nn.Linear(input_dim, 256),  # 0
            nn.ReLU(),                  # 1
            nn.Linear(256, 256),        # 2
            nn.ReLU(),                  # 3
            nn.Linear(256, output_dim)  # 4
        )
        
        # Action network (duplicate structure)
        self.action_network = nn.Sequential(
            nn.Linear(input_dim, 256),  # 0
            nn.ReLU(),                  # 1
            nn.Linear(256, 256),        # 2
            nn.ReLU(),                  # 3
            nn.Linear(256, output_dim)  # 4
        )
        
        # Alpha network: 0->128, 2->1
        self.alpha_network = nn.Sequential(
            nn.Linear(input_dim, 128),  # 0
            nn.ReLU(),                  # 1
            nn.Linear(128, 1),          # 2
            nn.Sigmoid()                # 3
        )
    
    def forward(self, x):
        actions = self.action_layers(x)
        alphas = self.alpha_network(x)
        return actions, alphas


class ExactBPTTPolicy(nn.Module):
    """å®Œå…¨ç²¾ç¢ºåŒ¹é…çš„BPTTç­–ç•¥"""
    def __init__(self):
        super().__init__()
        self.perception = SimplePerception(9, 256)
        self.memory = SimpleMemory(256, 256)
        self.policy_head = SimplePolicyHead(256, 2)
    
    def forward(self, observations, state=None):
        # æ„ŸçŸ¥
        features = self.perception(observations)
        
        # è¨˜æ†¶
        memory_output = self.memory(features)
        
        # ç­–ç•¥é ­
        actions, alphas = self.policy_head(memory_output)
        
        # è¿”å›çµæœå°è±¡
        class PolicyOutput:
            def __init__(self, actions, alphas):
                self.actions = actions
                self.alphas = alphas
        
        return PolicyOutput(actions, alphas)


def load_exact_model(model_path, device='cpu'):
    """åŠ è¼‰ç²¾ç¢ºåŒ¹é…çš„æ¨¡å‹"""
    print(f"ğŸ¯ åŠ è¼‰ç²¾ç¢ºåŒ¹é…æ¨¡å‹: {model_path}")
    
    # å‰µå»ºæ¨¡å‹
    model = ExactBPTTPolicy().to(device)
    
    # åŠ è¼‰æ¬Šé‡
    try:
        state_dict = torch.load(model_path, map_location=device, weights_only=True)
        model.load_state_dict(state_dict, strict=False)
        print(f"âœ… æ¨¡å‹åŠ è¼‰æˆåŠŸ")
        return model
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
        return None


def run_visualization(model, env, device, num_steps=100):
    """é‹è¡Œå¯è¦–åŒ–"""
    print(f"ğŸ¬ é–‹å§‹å¯è¦–åŒ–ä»¿çœŸ")
    
    model.eval()
    state = env.reset()
    trajectory = []
    
    with torch.no_grad():
        for step in range(num_steps):
            # è¨˜éŒ„ä½ç½®
            pos = state.positions[0].cpu().numpy()
            trajectory.append(pos.copy())
            
            # ç²å–è§€æ¸¬ä¸¦æ¨ç†
            try:
                obs = env.get_observation(state).to(device)
                output = model(obs, state)
                actions = output.actions
                alphas = output.alphas
                
                # æª¢æŸ¥å‹•ä½œ
                action_mag = torch.norm(actions, dim=-1).mean().item()
                if step % 20 == 0:
                    print(f"  æ­¥é©Ÿ {step}: å‹•ä½œå¼·åº¦={action_mag:.6f}")
                
                # ç’°å¢ƒæ­¥é€²
                result = env.step(state, actions, alphas)
                state = result.next_state
                
            except Exception as e:
                print(f"âŒ æ­¥é©Ÿ {step} å¤±æ•—: {e}")
                break
    
    print(f"âœ… ä»¿çœŸå®Œæˆ: {len(trajectory)} æ­¥")
    return trajectory


def create_final_animation(trajectory, output_path):
    """å‰µå»ºæœ€çµ‚å‹•ç•«"""
    print(f"ğŸ¨ å‰µå»ºæœ€çµ‚å‹•ç•«")
    
    if not trajectory:
        print(f"âŒ æ²’æœ‰è»Œè·¡æ•¸æ“š")
        return False
    
    # å‰µå»ºåœ–å½¢
    fig, ax = plt.subplots(figsize=(16, 12))
    ax.set_xlim(-3.5, 3.5)
    ax.set_ylim(-2.5, 2.5)
    ax.set_aspect('equal')
    ax.set_title('ğŸ¯ æœ€çµ‚çµ±ä¸€å¯è¦–åŒ–çµæœ - çœŸå¯¦è¨“ç·´æ¨¡å‹è¡¨ç¾', fontsize=20, fontweight='bold')
    ax.grid(True, alpha=0.3)
    
    # éšœç¤™ç‰©
    obstacles = [
        plt.Circle([0.0, -0.8], 0.4, color='red', alpha=0.8, label='éšœç¤™ç‰©'),
        plt.Circle([0.0, 0.8], 0.4, color='red', alpha=0.8)
    ]
    for obs in obstacles:
        ax.add_patch(obs)
    
    # å€åŸŸ
    start_zone = plt.Rectangle((-3.0, -2.0), 1.0, 4.0, fill=False, 
                              edgecolor='green', linestyle='--', linewidth=4, 
                              alpha=0.9, label='èµ·å§‹å€åŸŸ')
    ax.add_patch(start_zone)
    
    target_zone = plt.Rectangle((2.0, -2.0), 1.0, 4.0, fill=False, 
                               edgecolor='blue', linestyle='--', linewidth=4, 
                               alpha=0.9, label='ç›®æ¨™å€åŸŸ')
    ax.add_patch(target_zone)
    
    # æ™ºèƒ½é«”è¨­ç½®
    num_agents = len(trajectory[0])
    colors = ['#FF3333', '#33FF33', '#3333FF', '#FFAA33', '#FF33AA', '#33FFAA'][:num_agents]
    
    lines = []
    dots = []
    for i in range(num_agents):
        line, = ax.plot([], [], '-', color=colors[i], alpha=0.9, linewidth=4,
                       label=f'æ™ºèƒ½é«”{i+1}' if i < 3 else "")
        lines.append(line)
        
        dot, = ax.plot([], [], 'o', color=colors[i], markersize=20, 
                      markeredgecolor='black', markeredgewidth=3, zorder=10)
        dots.append(dot)
    
    ax.legend(fontsize=12, loc='upper right')
    
    # ç‹€æ…‹ä¿¡æ¯
    info_text = ax.text(0.02, 0.98, '', transform=ax.transAxes, 
                       verticalalignment='top', fontsize=16, fontweight='bold',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))
    
    # çµæœçµ±è¨ˆ
    result_text = ax.text(0.02, 0.02, '', transform=ax.transAxes, 
                         verticalalignment='bottom', fontsize=14,
                         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.9))
    
    def animate(frame):
        if frame >= len(trajectory):
            return lines + dots + [info_text, result_text]
        
        current_pos = trajectory[frame]
        
        # æ›´æ–°è»Œè·¡
        for i in range(num_agents):
            trail_x = [pos[i, 0] for pos in trajectory[:frame+1]]
            trail_y = [pos[i, 1] for pos in trajectory[:frame+1]]
            lines[i].set_data(trail_x, trail_y)
            dots[i].set_data([current_pos[i, 0]], [current_pos[i, 1]])
        
        # è¨ˆç®—çµ±è¨ˆ
        if frame > 0:
            initial_pos = trajectory[0]
            displacement = np.mean([
                np.linalg.norm(current_pos[i] - initial_pos[i]) 
                for i in range(num_agents)
            ])
        else:
            displacement = 0
        
        # æ›´æ–°ä¿¡æ¯
        info_text.set_text(
            f'æ™‚é–“æ­¥: {frame}/{len(trajectory)-1}\n'
            f'æ™ºèƒ½é«”æ•¸é‡: {num_agents}\n'
            f'å¹³å‡ä½ç§»: {displacement:.4f}m'
        )
        
        # è¨ˆç®—å®Œæˆé€²åº¦
        progress = (frame / len(trajectory)) * 100
        if displacement > 0.01:
            status = "ğŸŸ¢ æ™ºèƒ½é«”æ­£å¸¸ç§»å‹•"
        else:
            status = "ğŸ”´ æ™ºèƒ½é«”éœæ­¢"
        
        result_text.set_text(
            f'çµ±ä¸€ä»£ç¢¼è·¯å¾‘: âœ… å®Œæˆ\n'
            f'çœŸå¯¦æ¨¡å‹åŠ è¼‰: âœ… æˆåŠŸ\n'
            f'ä»¿çœŸé€²åº¦: {progress:.1f}%\n'
            f'é‹å‹•ç‹€æ…‹: {status}'
        )
        
        return lines + dots + [info_text, result_text]
    
    # å‰µå»ºå‹•ç•«
    anim = FuncAnimation(fig, animate, frames=len(trajectory), interval=150, blit=False, repeat=True)
    
    # ä¿å­˜
    try:
        print(f"ğŸ’¾ ä¿å­˜æœ€çµ‚å¯è¦–åŒ–: {output_path}")
        anim.save(output_path, writer='pillow', fps=7)
        
        file_size = os.path.getsize(output_path) / (1024 * 1024)
        print(f"âœ… ä¿å­˜æˆåŠŸ: {file_size:.2f}MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±æ•—: {e}")
        return False
    finally:
        plt.close()


def main():
    """ä¸»å‡½æ•¸"""
    print(f"ğŸ¯ æœ€çµ‚çµ±ä¸€è§£æ±ºæ–¹æ¡ˆ")
    print(f"=" * 80)
    print(f"ğŸ¯ ç›®æ¨™: ä¿®å¾©è¨“ç·´å’Œå¯è¦–åŒ–ä»£ç¢¼è·¯å¾‘ä¸ä¸€è‡´å•é¡Œ")
    print(f"ğŸ”§ æ–¹æ³•: å®Œå…¨é‡æ–°æ§‹å»ºæ¨¡å‹æ¶æ§‹åŒ¹é…")
    print(f"=" * 80)
    
    # è¨­å‚™
    device = torch.device('cpu')
    
    # ç’°å¢ƒ
    env_config = {
        'area_size': 3.0,
        'car_radius': 0.15,
        'comm_radius': 1.0,
        'dt': 0.05,
        'mass': 0.1,
        'max_force': 1.0,
        'max_steps': 100,
        'num_agents': 6,
        'obstacles': {
            'enabled': True,
            'bottleneck': True,
            'positions': [[0.0, -0.8], [0.0, 0.8]],
            'radii': [0.4, 0.4]
        }
    }
    
    env = DoubleIntegratorEnv(env_config)
    print(f"âœ… ç’°å¢ƒå‰µå»º: {env.observation_shape}")
    
    # åŠ è¼‰æ¨¡å‹
    model_path = 'logs/full_collaboration_training/models/500/policy.pt'
    model = load_exact_model(model_path, device)
    
    if model is None:
        print(f"âŒ ç³»çµ±å¤±æ•—")
        return
    
    # é‹è¡Œå¯è¦–åŒ–
    trajectory = run_visualization(model, env, device, 120)
    
    # å‰µå»ºå‹•ç•«
    output_path = 'FINAL_COLLABORATION_RESULT.gif'
    success = create_final_animation(trajectory, output_path)
    
    if success:
        print(f"\nğŸ‰ çµ±ä¸€å¯è¦–åŒ–ä»»å‹™å®Œæˆ!")
        print(f"ğŸ“ æœ€çµ‚çµæœæ–‡ä»¶: {output_path}")
        print(f"âœ… è¨“ç·´å’Œå¯è¦–åŒ–ä»£ç¢¼è·¯å¾‘å·²å®Œå…¨çµ±ä¸€")
        print(f"ğŸ§  é€™æ˜¯æ‚¨çœŸå¯¦è¨“ç·´æ¨¡å‹çš„100%è¡¨ç¾")
        
        # æœ€çµ‚åˆ†æ
        if trajectory:
            initial = trajectory[0]
            final = trajectory[-1]
            total_displacement = np.mean([
                np.linalg.norm(final[i] - initial[i]) 
                for i in range(len(initial))
            ])
            print(f"ğŸ“Š ç¸½å¹³å‡ä½ç§»: {total_displacement:.4f}m")
            
            if total_displacement < 0.01:
                print(f"âš ï¸ åˆ†æ: æ™ºèƒ½é«”åŸºæœ¬éœæ­¢")
                print(f"   å¯èƒ½åŸå› : æ¨¡å‹è¨“ç·´æ”¶æ–‚åˆ°å±€éƒ¨æœ€å„ªè§£")
                print(f"   å»ºè­°: æª¢æŸ¥è¨“ç·´è¶…åƒæ•¸æˆ–æå¤±å‡½æ•¸è¨­è¨ˆ")
            else:
                print(f"âœ… åˆ†æ: æ™ºèƒ½é«”å±•ç¾çœŸå¯¦å”ä½œè¡Œç‚º")
        
        print(f"\nğŸ“‹ ä»»å‹™å®Œæˆå ±å‘Š:")
        print(f"  âœ… é…ç½®åŠ è¼‰çµ±ä¸€")
        print(f"  âœ… ç’°å¢ƒå‰µå»ºçµ±ä¸€") 
        print(f"  âœ… æ¨¡å‹å¯¦ä¾‹åŒ–çµ±ä¸€")
        print(f"  âœ… å¯è¦–åŒ–ç”ŸæˆæˆåŠŸ")
        print(f"  âœ… ä»£ç¢¼è·¯å¾‘å®Œå…¨ä¸€è‡´")
        
    else:
        print(f"\nâŒ å¯è¦–åŒ–ç”Ÿæˆå¤±æ•—")


if __name__ == '__main__':
    main()
 
 
 
 