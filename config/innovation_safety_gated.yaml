# Innovation Safety Gated Configuration
# Core Innovation: Safety-Gated Alpha Regularization
# Strategy: Apply alpha regularization only when system is already safe, allowing alpha to increase freely when safety is compromised

# å®éªŒåç§°
run_name: "innovation_safety_gated"

# ç¯å¢ƒå‚æ•°
env:
  num_agents: 2                   # å‡å°‘æ™ºèƒ½ä½“æ•°é‡ä»¥ç®€åŒ–å­¦ä¹ 
  area_size: 2.0                  # å¢å¤§ç¯å¢ƒä»¥æä¾›æ›´å¤šç©ºé—´
  agent_radius: 0.2               # æ™ºèƒ½ä½“åŠå¾„
  comm_radius: 1.0                # é€šä¿¡åŠå¾„
  mass: 0.1                       # æ™ºèƒ½ä½“è´¨é‡
  dt: 0.05                        # ä»¿çœŸæ—¶é—´æ­¥é•¿
  max_force: 1.0                  # æœ€å¤§åŠ›
  cbf_alpha: 1.0                  # CBFå®‰å…¨çº¦æŸçš„Alphaå‚æ•°
  max_steps: 300                  # æœ€å¤§æ­¥æ•°

  # éšœç¤™ç‰©é…ç½®ï¼ˆç¦ç”¨ä»¥åŒ¹é…6Dæ¨¡å‹ï¼‰
  obstacles:
    enabled: false
    num_obstacles: 0
    positions: []
    radii: []

# ç½‘ç»œå‚æ•°ï¼ˆåŒ¹é…å·²è®­ç»ƒæ¨¡å‹æ¶æ„ï¼‰
networks:
  policy:
    perception:
      use_vision: false
      input_dim: 6                # æ— éšœç¢ç‰©ç¯å¢ƒï¼šstate(4) + goal(2)
      hidden_dim: 64
      activation: relu
    memory:
      hidden_dim: 128
      num_layers: 1
    policy_head:
      input_dim: 128
      output_dim: 2
      hidden_dims: [256]
      activation: relu
      predict_alpha: true

  cbf:
    alpha: 1.0
    eps: 0.02
    safety_margin: 0.2
    use_qp: true

# è®­ç»ƒå‚æ•°
training:
  training_steps: 2000            # å¢åŠ è®­ç»ƒæ­¥æ•°ä»¥å……åˆ†éªŒè¯åˆ›æ–°ç‚¹
  horizon_length: 50              # BPTT rollouté•¿åº¦
  eval_horizon: 300               # è¯„ä¼°rollouté•¿åº¦
  eval_interval: 100              # è¯„ä¼°é—´éš”
  save_interval: 500              # æ¨¡å‹ä¿å­˜é—´éš”
  learning_rate: 0.0005           # é™ä½å­¦ä¹ ç‡ä»¥è·å¾—æ›´ç¨³å®šçš„è®­ç»ƒ
  max_grad_norm: 1.0              # æ¢¯åº¦è£å‰ª
  
  # å­¦ä¹ ç‡è°ƒåº¦å™¨
  use_lr_scheduler: true
  lr_step_size: 1000
  lr_gamma: 0.8
  
  # æ—¶åºç¨³å®šæ€§çš„æ¢¯åº¦è¡°å‡
  gradient_decay_rate: 0.95

# æŸå¤±æƒé‡ - åŸºäºRebalance Cçš„ä¼˜ç§€é…ç½®
loss_weights:
  # è°ƒæ•´æƒé‡ - åŸºäºç­–ç•¥C
  goal_weight: 0.7                # å¹³è¡¡çš„ç›®æ ‡å¯¼å‘
  safety_weight: 10.0             # ä¿æŒé«˜å®‰å…¨æƒé‡
  
  # æ§åˆ¶æ­£åˆ™åŒ–æƒé‡
  acceleration_loss_weight: 0.005 # æ›´å°‘åŠ é€Ÿåº¦çº¦æŸ
  jerk_loss_weight: 0.01          # æ˜¾è‘—å‡å°‘æŠ–åŠ¨çº¦æŸ
  
  # å…¶ä»–ç°æœ‰æƒé‡
  control_weight: 0.1             # æ§åˆ¶åŠªåŠ›æŸå¤±
  alpha_reg_weight: 0.01          # alphaæ­£åˆ™åŒ–æƒé‡ (å°†è¢«é—¨æ§æœºåˆ¶æ§åˆ¶)
  progress_weight: 0.05           # è¿›åº¦å¥–åŠ±æƒé‡

# ğŸš€ CORE INNOVATION: å®‰å…¨é—¨æ§Alphaæ­£åˆ™åŒ–
use_safety_gated_alpha_reg: true  # æ¿€æ´»æˆ‘ä»¬çš„åˆ›æ–°é€»è¾‘
safety_loss_threshold: 0.01       # å®‰å…¨é˜ˆå€¼ - ä½äºæ­¤å€¼æ‰åº”ç”¨alphaæ­£åˆ™åŒ–

# CBFå‚æ•°
cbf_alpha: 1.0

# æ—¥å¿—é…ç½®
enable_episode_logging: true

# Wandbé…ç½®
wandb_config:
  project: "gcbf-innovation-experiments"
  offline: true                   # ç¦»çº¿æ¨¡å¼

# å®éªŒå…ƒæ•°æ®
experiment_type: "safety_gated_innovation"
description: "Core Innovation: Safety-Gated Alpha Regularization - Apply alpha penalty only when system is safe, allowing free alpha increase during safety-critical situations"
