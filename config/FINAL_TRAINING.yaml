# FINAL TRAINING Configuration for Championship Model
# Ultimate Training: Dual Innovation (Safety-Gated Alpha + Adaptive Safety Margin)
# Goal: Push the performance to absolute limits with extended training

# å®éªŒåç§° - æ ‡è®°ä¸ºæœ€ç»ˆå†³æˆ˜ç‰ˆæœ¬
run_name: "FINAL_TRAINING_CHAMPIONSHIP"

# ç¯å¢ƒå‚æ•° - ä½¿ç”¨å·²éªŒè¯çš„æœ€ä½³é…ç½®
env:
  num_agents: 2                   # å‡å°‘æ™ºèƒ½ä½“æ•°é‡ä»¥ç®€åŒ–å­¦ä¹ 
  area_size: 2.0                  # å¢å¤§ç¯å¢ƒä»¥æä¾›æ›´å¤šç©ºé—´
  agent_radius: 0.2               # æ™ºèƒ½ä½“åŠå¾„
  comm_radius: 1.0                # é€šä¿¡åŠå¾„
  mass: 0.1                       # æ™ºèƒ½ä½“è´¨é‡
  dt: 0.05                        # ä»¿çœŸæ—¶é—´æ­¥é•¿
  max_force: 1.0                  # æœ€å¤§åŠ›
  cbf_alpha: 1.0                  # CBFå®‰å…¨çº¦æŸçš„Alphaå‚æ•°
  max_steps: 300                  # æœ€å¤§æ­¥æ•°

  # éšœç¤™ç‰©é…ç½®ï¼ˆç¦ç”¨ä»¥åŒ¹é…6Dæ¨¡å‹ï¼‰
  obstacles:
    enabled: false
    num_obstacles: 0
    positions: []
    radii: []

# ç½‘ç»œå‚æ•°ï¼ˆåŒ¹é…å·²è®­ç»ƒæ¨¡å‹æ¶æ„ï¼‰
networks:
  policy:
    perception:
      use_vision: false
      input_dim: 6                # æ— éšœç¢ç‰©ç¯å¢ƒï¼šstate(4) + goal(2)
      hidden_dim: 64
      activation: relu
    memory:
      hidden_dim: 128
      num_layers: 1
    policy_head:
      input_dim: 128
      output_dim: 2
      hidden_dims: [256]
      activation: relu
      predict_alpha: true
      predict_margin: true        # ğŸš€ NEW: å¯ç”¨åŠ¨æ€å®‰å…¨è£•åº¦é¢„æµ‹
      margin_hidden_dim: 64       # åŠ¨æ€è£•åº¦ç½‘ç»œçš„éšè—å±‚ç»´åº¦

  cbf:
    alpha: 1.0
    eps: 0.02
    safety_margin: 0.2            # åŸºç¡€å®‰å…¨è£•åº¦ï¼ˆå°†è¢«åŠ¨æ€è¦†ç›–ï¼‰
    use_qp: true

# è®­ç»ƒå‚æ•° - ğŸ† FINAL CHAMPIONSHIP TRAINING
training:
  training_steps: 20000           # ğŸš€ 10å€è®­ç»ƒæ­¥æ•° - æ¨å‘æé™ï¼
  horizon_length: 50              # BPTT rollouté•¿åº¦
  eval_horizon: 300               # è¯„ä¼°rollouté•¿åº¦
  eval_interval: 500              # è¯„ä¼°é—´éš” - å¢åŠ é—´éš”ä»¥é€‚åº”é•¿è®­ç»ƒ
  save_interval: 2000             # æ¨¡å‹ä¿å­˜é—´éš” - å¢åŠ é—´éš”
  learning_rate: 0.0005           # é™ä½å­¦ä¹ ç‡ä»¥è·å¾—æ›´ç¨³å®šçš„è®­ç»ƒ
  max_grad_norm: 1.0              # æ¢¯åº¦è£å‰ª
  
  # å­¦ä¹ ç‡è°ƒåº¦å™¨ - é€‚åº”é•¿è®­ç»ƒ
  use_lr_scheduler: true
  lr_step_size: 5000              # å¢åŠ è°ƒåº¦é—´éš”
  lr_gamma: 0.8
  
  # æ—¶åºç¨³å®šæ€§çš„æ¢¯åº¦è¡°å‡
  gradient_decay_rate: 0.95

# æŸå¤±æƒé‡ - åŸºäºä¹‹å‰æˆåŠŸçš„é…ç½®
loss_weights:
  # è°ƒæ•´æƒé‡ - åŸºäºå‰é¢çš„æˆåŠŸé…ç½®
  goal_weight: 0.7                # å¹³è¡¡çš„ç›®æ ‡å¯¼å‘
  safety_weight: 10.0             # ä¿æŒé«˜å®‰å…¨æƒé‡
  
  # æ§åˆ¶æ­£åˆ™åŒ–æƒé‡
  acceleration_loss_weight: 0.005 # æ›´å°‘åŠ é€Ÿåº¦çº¦æŸ
  jerk_loss_weight: 0.01          # æ˜¾è‘—å‡å°‘æŠ–åŠ¨çº¦æŸ
  
  # å…¶ä»–ç°æœ‰æƒé‡
  control_weight: 0.1             # æ§åˆ¶åŠªåŠ›æŸå¤±
  alpha_reg_weight: 0.01          # alphaæ­£åˆ™åŒ–æƒé‡
  progress_weight: 0.05           # è¿›åº¦å¥–åŠ±æƒé‡
  
  # ğŸš€ NEW: åŠ¨æ€å®‰å…¨è£•åº¦æ­£åˆ™åŒ–æƒé‡
  margin_reg_weight: 0.05         # ç”¨äºçº¦æŸåŠ¨æ€è£•åº¦çš„æ–°æŸå¤±é¡¹æƒé‡

# ğŸš€ CORE INNOVATION 1: è‡ªé€‚åº”å®‰å…¨è£•åº¦å‚æ•°
use_adaptive_margin: true         # æ¿€æ´»æ–°é€»è¾‘
min_safety_margin: 0.15           # åŠ¨æ€è£•åº¦çš„æœ€å°å€¼
max_safety_margin: 0.4            # åŠ¨æ€è£•åº¦çš„æœ€å¤§å€¼

# ğŸš€ CORE INNOVATION 2: ç»§æ‰¿å®‰å…¨é—¨æ§åˆ›æ–°
use_safety_gated_alpha_reg: true  # ä¿æŒä¹‹å‰çš„åˆ›æ–°
safety_loss_threshold: 0.01       # å®‰å…¨é˜ˆå€¼

# CBFå‚æ•°
cbf_alpha: 1.0

# æ—¥å¿—é…ç½®
enable_episode_logging: true

# Wandbé…ç½®
wandb_config:
  project: "gcbf-final-championship-training"
  offline: true                   # ç¦»çº¿æ¨¡å¼

# å®éªŒå…ƒæ•°æ®
experiment_type: "final_championship_training"
description: "FINAL CHAMPIONSHIP TRAINING: Dual Innovation (Safety-Gated Alpha + Adaptive Safety Margin) - 20K steps training to push performance to absolute limits"
