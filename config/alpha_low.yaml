# Configuration file for BPTT training with low CBF alpha
run_name: "GCBF+_BTN_BPTT_Low_Alpha"

# Environment parameters
env:
  num_agents: 8                   # Number of agents in the environment
  area_size: 1.0                  # Size of the square environment
  car_radius: 0.05                # Radius of each agent (for collision detection)
  comm_radius: 0.5                # Communication radius for graph construction
  mass: 0.1                       # Mass of each agent
  dt: 0.03                        # Simulation timestep
  cbf_alpha: 0.5                  # Low alpha value for CBF safety constraints

# Networks parameters
networks:
  # Policy GNN parameters
  policy:
    input_dim: 9                  # state_dim (4) + goal position (2) + obstacle info (3)
    node_dim: 7                   # Position (2) + Velocity (2) + Goal direction (2) + Agent indicator (1)
    edge_dim: 4                   # Relative position (2) + Relative velocity (2)
    hidden_dim: 64                # Dimension of hidden layers
    n_layers: 2                   # Number of GNN layers
    msg_hidden_sizes: [64, 64]    # Hidden sizes for message network
    aggr_hidden_sizes: [64]       # Hidden sizes for attention network
    update_hidden_sizes: [64, 64] # Hidden sizes for update network
  
  # CBF GNN parameters
  cbf:
    node_dim: 7                   # Position (2) + Velocity (2) + Goal direction (2) + Agent indicator (1)
    edge_dim: 4                   # Relative position (2) + Relative velocity (2)
    hidden_dim: 64                # Dimension of hidden layers
    n_layers: 2                   # Number of GNN layers
    msg_hidden_sizes: [64, 64]    # Hidden sizes for message network
    aggr_hidden_sizes: [64]       # Hidden sizes for attention network
    update_hidden_sizes: [64, 64] # Hidden sizes for update network

# Training parameters
training:
  training_steps: 1000            # Reduced training steps for quick experiment
  horizon_length: 50              # Horizon length for BPTT rollouts
  eval_horizon: 100               # Horizon length for evaluation rollouts
  eval_interval: 100              # Interval between evaluations
  save_interval: 500              # Interval between model saves
  learning_rate: 0.001            # Learning rate for Adam optimizer
  max_grad_norm: 1.0              # Maximum gradient norm (for clipping)
  
  # Learning rate scheduler
  use_lr_scheduler: true          # Whether to use learning rate scheduler
  lr_step_size: 500               # Step size for learning rate scheduler
  lr_gamma: 0.5                   # Multiplier for learning rate scheduler
  
  # Gradient decay for temporal stability
  gradient_decay_rate: 0.95       # Rate at which gradients decay through time

  # Loss weights
  goal_weight: 1.0                # Weight for goal reaching loss
  safety_weight: 10.0             # Weight for safety loss (CBF violation)
  control_weight: 0.1             # Weight for control effort loss
  jerk_weight: 0.05               # Weight for jerk penalty (rate of change of action)