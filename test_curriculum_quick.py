#!/usr/bin/env python3
"""
å¿«é€Ÿæ¸¬è©¦èª²ç¨‹å­¸ç¿’æ¡†æ¶
é‹è¡Œå°è¦æ¨¡å¯¦é©—ä»¥é©—è­‰ç³»çµ±å·¥ä½œæ­£å¸¸
"""

import subprocess
import sys
import os
import time

def run_command(cmd, description):
    """é‹è¡Œå‘½ä»¤ä¸¦è™•ç†éŒ¯èª¤"""
    print(f"\nğŸ”„ {description}")
    print(f"ğŸ“ åŸ·è¡Œå‘½ä»¤: {cmd}")
    
    start_time = time.time()
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    duration = time.time() - start_time
    
    if result.returncode == 0:
        print(f"âœ… {description} æˆåŠŸ ({duration:.1f}s)")
        return True
    else:
        print(f"âŒ {description} å¤±æ•—")
        print(f"éŒ¯èª¤è¼¸å‡º: {result.stderr}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§ª èª²ç¨‹å­¸ç¿’æ¡†æ¶å¿«é€Ÿæ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦é…ç½®
    device = "cpu"
    seed = 42
    
    # å‰µå»ºå¿…è¦ç›®éŒ„
    os.makedirs("logs/test_curriculum", exist_ok=True)
    os.makedirs("results", exist_ok=True)
    
    # ===== æ¸¬è©¦1: é è¨“ç·´éšæ®µ =====
    print("\nğŸ“š æ¸¬è©¦éšæ®µ1: é è¨“ç·´ï¼ˆç°¡åŒ–ç‰ˆï¼‰")
    
    # ä¿®æ”¹é è¨“ç·´é…ç½®ç‚ºè¶…å¿«é€Ÿç‰ˆæœ¬
    quick_pretrain_config = """
env:
  num_agents: 4
  area_size: 1.5
  car_radius: 0.05
  comm_radius: 0.5
  mass: 0.1
  dt: 0.05
  obstacles:
    enabled: false

training:
  training_steps: 100  # è¶…çŸ­è¨“ç·´
  horizon_length: 10
  learning_rate: 0.01
  eval_interval: 50
  save_interval: 50
  
loss_weights:
  goal_weight: 1.0
  safety_weight: 2.0
  control_weight: 0.1
  jerk_weight: 0.02
  alpha_reg_weight: 0.01
  progress_weight: 0.2
"""
    
    # ä¿å­˜å¿«é€Ÿé…ç½®
    with open("config/quick_pretrain_test.yaml", "w") as f:
        f.write(quick_pretrain_config)
    
    # é‹è¡Œé è¨“ç·´
    cmd1 = f"python train_bptt.py --config config/quick_pretrain_test.yaml --device {device} --log_dir logs/test_curriculum/pretrain --seed {seed}"
    
    if not run_command(cmd1, "å¿«é€Ÿé è¨“ç·´æ¸¬è©¦"):
        print("âŒ é è¨“ç·´æ¸¬è©¦å¤±æ•—ï¼Œåœæ­¢æ¸¬è©¦")
        return False
    
    # ===== æ¸¬è©¦2: Fine-tuningéšæ®µ =====
    print("\nğŸ¯ æ¸¬è©¦éšæ®µ2: Fine-tuningï¼ˆæ·»åŠ éšœç¤™ç‰©ï¼‰")
    
    # ä¿®æ”¹fine-tuningé…ç½®
    quick_finetune_config = """
env:
  num_agents: 4
  area_size: 1.5
  car_radius: 0.05
  comm_radius: 0.5
  mass: 0.1
  dt: 0.05
  obstacles:
    enabled: true
    positions: [[0.0, 0.0]]
    radii: [0.2]

training:
  training_steps: 100  # è¶…çŸ­fine-tuning
  horizon_length: 10
  learning_rate: 0.005
  eval_interval: 50
  save_interval: 50
  
loss_weights:
  goal_weight: 1.0
  safety_weight: 5.0
  control_weight: 0.1
  jerk_weight: 0.02
  alpha_reg_weight: 0.01
  progress_weight: 0.15
"""
    
    # ä¿å­˜fine-tuningé…ç½®
    with open("config/quick_finetune_test.yaml", "w") as f:
        f.write(quick_finetune_config)
    
    # é‹è¡Œfine-tuning
    cmd2 = f"python train_bptt.py --config config/quick_finetune_test.yaml --device {device} --log_dir logs/test_curriculum/finetune --load_pretrained_model_from logs/test_curriculum/pretrain --seed {seed}"
    
    if not run_command(cmd2, "å¿«é€ŸFine-tuningæ¸¬è©¦"):
        print("âŒ Fine-tuningæ¸¬è©¦å¤±æ•—")
        return False
    
    # ===== æ¸¬è©¦3: å¯è¦–åŒ–ç”Ÿæˆ =====
    print("\nğŸ¨ æ¸¬è©¦éšæ®µ3: å¯è¦–åŒ–ç”Ÿæˆ")
    
    cmd3 = f"python visualize_bptt.py --model_dir logs/test_curriculum/finetune --output results/test_curriculum_result.gif --device {device}"
    
    if not run_command(cmd3, "å¯è¦–åŒ–ç”Ÿæˆæ¸¬è©¦"):
        print("âš ï¸ å¯è¦–åŒ–æ¸¬è©¦å¤±æ•—ï¼Œä½†æ ¸å¿ƒåŠŸèƒ½å¯èƒ½æ­£å¸¸")
    
    # ===== æ¸¬è©¦çµæœ =====
    print("\nğŸ“Š æ¸¬è©¦çµæœç¸½çµ")
    print("=" * 50)
    
    # æª¢æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
    pretrain_exists = os.path.exists("logs/test_curriculum/pretrain/models")
    finetune_exists = os.path.exists("logs/test_curriculum/finetune/models")
    viz_exists = os.path.exists("results/test_curriculum_result.gif")
    
    print(f"âœ… é è¨“ç·´æ¨¡å‹: {'å­˜åœ¨' if pretrain_exists else 'ä¸å­˜åœ¨'}")
    print(f"âœ… Fine-tuningæ¨¡å‹: {'å­˜åœ¨' if finetune_exists else 'ä¸å­˜åœ¨'}")
    print(f"âœ… å¯è¦–åŒ–æ–‡ä»¶: {'å­˜åœ¨' if viz_exists else 'ä¸å­˜åœ¨'}")
    
    if pretrain_exists and finetune_exists:
        print("\nğŸ‰ èª²ç¨‹å­¸ç¿’æ¡†æ¶æ¸¬è©¦æˆåŠŸï¼")
        print("ğŸš€ ç¾åœ¨å¯ä»¥é‹è¡Œå®Œæ•´çš„å¯¦é©—ç®¡é“ï¼š")
        print("   Windows: run_curriculum_experiments.bat")
        print("   Linux/Mac: bash run_curriculum_experiments.sh")
        return True
    else:
        print("\nâŒ èª²ç¨‹å­¸ç¿’æ¡†æ¶æ¸¬è©¦å¤±æ•—")
        print("è«‹æª¢æŸ¥éŒ¯èª¤æ—¥èªŒä¸¦ä¿®å¾©å•é¡Œ")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
 
"""
å¿«é€Ÿæ¸¬è©¦èª²ç¨‹å­¸ç¿’æ¡†æ¶
é‹è¡Œå°è¦æ¨¡å¯¦é©—ä»¥é©—è­‰ç³»çµ±å·¥ä½œæ­£å¸¸
"""

import subprocess
import sys
import os
import time

def run_command(cmd, description):
    """é‹è¡Œå‘½ä»¤ä¸¦è™•ç†éŒ¯èª¤"""
    print(f"\nğŸ”„ {description}")
    print(f"ğŸ“ åŸ·è¡Œå‘½ä»¤: {cmd}")
    
    start_time = time.time()
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    duration = time.time() - start_time
    
    if result.returncode == 0:
        print(f"âœ… {description} æˆåŠŸ ({duration:.1f}s)")
        return True
    else:
        print(f"âŒ {description} å¤±æ•—")
        print(f"éŒ¯èª¤è¼¸å‡º: {result.stderr}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§ª èª²ç¨‹å­¸ç¿’æ¡†æ¶å¿«é€Ÿæ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦é…ç½®
    device = "cpu"
    seed = 42
    
    # å‰µå»ºå¿…è¦ç›®éŒ„
    os.makedirs("logs/test_curriculum", exist_ok=True)
    os.makedirs("results", exist_ok=True)
    
    # ===== æ¸¬è©¦1: é è¨“ç·´éšæ®µ =====
    print("\nğŸ“š æ¸¬è©¦éšæ®µ1: é è¨“ç·´ï¼ˆç°¡åŒ–ç‰ˆï¼‰")
    
    # ä¿®æ”¹é è¨“ç·´é…ç½®ç‚ºè¶…å¿«é€Ÿç‰ˆæœ¬
    quick_pretrain_config = """
env:
  num_agents: 4
  area_size: 1.5
  car_radius: 0.05
  comm_radius: 0.5
  mass: 0.1
  dt: 0.05
  obstacles:
    enabled: false

training:
  training_steps: 100  # è¶…çŸ­è¨“ç·´
  horizon_length: 10
  learning_rate: 0.01
  eval_interval: 50
  save_interval: 50
  
loss_weights:
  goal_weight: 1.0
  safety_weight: 2.0
  control_weight: 0.1
  jerk_weight: 0.02
  alpha_reg_weight: 0.01
  progress_weight: 0.2
"""
    
    # ä¿å­˜å¿«é€Ÿé…ç½®
    with open("config/quick_pretrain_test.yaml", "w") as f:
        f.write(quick_pretrain_config)
    
    # é‹è¡Œé è¨“ç·´
    cmd1 = f"python train_bptt.py --config config/quick_pretrain_test.yaml --device {device} --log_dir logs/test_curriculum/pretrain --seed {seed}"
    
    if not run_command(cmd1, "å¿«é€Ÿé è¨“ç·´æ¸¬è©¦"):
        print("âŒ é è¨“ç·´æ¸¬è©¦å¤±æ•—ï¼Œåœæ­¢æ¸¬è©¦")
        return False
    
    # ===== æ¸¬è©¦2: Fine-tuningéšæ®µ =====
    print("\nğŸ¯ æ¸¬è©¦éšæ®µ2: Fine-tuningï¼ˆæ·»åŠ éšœç¤™ç‰©ï¼‰")
    
    # ä¿®æ”¹fine-tuningé…ç½®
    quick_finetune_config = """
env:
  num_agents: 4
  area_size: 1.5
  car_radius: 0.05
  comm_radius: 0.5
  mass: 0.1
  dt: 0.05
  obstacles:
    enabled: true
    positions: [[0.0, 0.0]]
    radii: [0.2]

training:
  training_steps: 100  # è¶…çŸ­fine-tuning
  horizon_length: 10
  learning_rate: 0.005
  eval_interval: 50
  save_interval: 50
  
loss_weights:
  goal_weight: 1.0
  safety_weight: 5.0
  control_weight: 0.1
  jerk_weight: 0.02
  alpha_reg_weight: 0.01
  progress_weight: 0.15
"""
    
    # ä¿å­˜fine-tuningé…ç½®
    with open("config/quick_finetune_test.yaml", "w") as f:
        f.write(quick_finetune_config)
    
    # é‹è¡Œfine-tuning
    cmd2 = f"python train_bptt.py --config config/quick_finetune_test.yaml --device {device} --log_dir logs/test_curriculum/finetune --load_pretrained_model_from logs/test_curriculum/pretrain --seed {seed}"
    
    if not run_command(cmd2, "å¿«é€ŸFine-tuningæ¸¬è©¦"):
        print("âŒ Fine-tuningæ¸¬è©¦å¤±æ•—")
        return False
    
    # ===== æ¸¬è©¦3: å¯è¦–åŒ–ç”Ÿæˆ =====
    print("\nğŸ¨ æ¸¬è©¦éšæ®µ3: å¯è¦–åŒ–ç”Ÿæˆ")
    
    cmd3 = f"python visualize_bptt.py --model_dir logs/test_curriculum/finetune --output results/test_curriculum_result.gif --device {device}"
    
    if not run_command(cmd3, "å¯è¦–åŒ–ç”Ÿæˆæ¸¬è©¦"):
        print("âš ï¸ å¯è¦–åŒ–æ¸¬è©¦å¤±æ•—ï¼Œä½†æ ¸å¿ƒåŠŸèƒ½å¯èƒ½æ­£å¸¸")
    
    # ===== æ¸¬è©¦çµæœ =====
    print("\nğŸ“Š æ¸¬è©¦çµæœç¸½çµ")
    print("=" * 50)
    
    # æª¢æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
    pretrain_exists = os.path.exists("logs/test_curriculum/pretrain/models")
    finetune_exists = os.path.exists("logs/test_curriculum/finetune/models")
    viz_exists = os.path.exists("results/test_curriculum_result.gif")
    
    print(f"âœ… é è¨“ç·´æ¨¡å‹: {'å­˜åœ¨' if pretrain_exists else 'ä¸å­˜åœ¨'}")
    print(f"âœ… Fine-tuningæ¨¡å‹: {'å­˜åœ¨' if finetune_exists else 'ä¸å­˜åœ¨'}")
    print(f"âœ… å¯è¦–åŒ–æ–‡ä»¶: {'å­˜åœ¨' if viz_exists else 'ä¸å­˜åœ¨'}")
    
    if pretrain_exists and finetune_exists:
        print("\nğŸ‰ èª²ç¨‹å­¸ç¿’æ¡†æ¶æ¸¬è©¦æˆåŠŸï¼")
        print("ğŸš€ ç¾åœ¨å¯ä»¥é‹è¡Œå®Œæ•´çš„å¯¦é©—ç®¡é“ï¼š")
        print("   Windows: run_curriculum_experiments.bat")
        print("   Linux/Mac: bash run_curriculum_experiments.sh")
        return True
    else:
        print("\nâŒ èª²ç¨‹å­¸ç¿’æ¡†æ¶æ¸¬è©¦å¤±æ•—")
        print("è«‹æª¢æŸ¥éŒ¯èª¤æ—¥èªŒä¸¦ä¿®å¾©å•é¡Œ")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
 
 
 
 