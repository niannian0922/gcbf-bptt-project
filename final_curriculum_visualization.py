#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Final Curriculum Learning Visualization
é‡æ§‹å¾Œçš„æœ€çµ‚èª²ç¨‹å­¸ç¿’å¯è¦–åŒ–è…³æœ¬

ä½¿ç”¨çµ±ä¸€çš„æ¨ç†å·¥å…·ï¼Œç¢ºä¿å®Œç¾çš„æ¨¡å‹åŠ è¼‰å’Œä»¿çœŸ
"""

import os
import sys
import torch
import yaml
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import matplotlib.patches as patches
from pathlib import Path

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from gcbfplus.env import DoubleIntegratorEnv
from gcbfplus.utils.inference import load_model_and_config, run_simulation_for_visualization


def create_final_animation(trajectories, obstacles, env_config, save_path="FINAL_COLLABORATION_RESULT.mp4"):
    """å‰µå»ºæœ€çµ‚å¯è¦–åŒ–å‹•ç•«"""
    print(f"ğŸ¨ å‰µå»ºæœ€çµ‚å‹•ç•«: {save_path}")
    
    # è¨­ç½®åœ–å½¢
    fig, ax = plt.subplots(figsize=(14, 12))
    
    # ç’°å¢ƒåƒæ•¸
    world_size = env_config['env'].get('world_size', 4.0)
    agent_radius = env_config['env'].get('agent_radius', 0.1)
    goal_radius = env_config['env'].get('goal_radius', 0.2)
    
    # è¨­ç½®åæ¨™è»¸
    ax.set_xlim(-0.3, world_size + 0.3)
    ax.set_ylim(-0.3, world_size + 0.3)
    ax.set_aspect('equal')
    ax.grid(True, alpha=0.3, linestyle='--')
    
    # è¨­ç½®æ¨™é¡Œå’Œæ¨™ç±¤
    ax.set_title('ğŸ“ Final Curriculum Learning Result\nMulti-Agent Collaborative Navigation with Obstacle Avoidance\n' + 
                'èª²ç¨‹å­¸ç¿’æœ€çµ‚æˆæœ - å¤šæ™ºèƒ½é«”å”ä½œé¿éšœå°èˆª', 
                fontsize=18, fontweight='bold', pad=20)
    ax.set_xlabel('X Position (meters)', fontsize=14, fontweight='bold')
    ax.set_ylabel('Y Position (meters)', fontsize=14, fontweight='bold')
    
    # ç¹ªè£½éšœç¤™ç‰©
    for i, obs in enumerate(obstacles):
        circle = patches.Circle(obs['center'], obs['radius'], color='red', alpha=0.8, 
                              edgecolor='darkred', linewidth=2,
                              label='Obstacles' if i == 0 else "")
        ax.add_patch(circle)
    
    # å‡è¨­ç›®æ¨™å€åŸŸï¼ˆæ ¹æ“šæœ€çµ‚ä½ç½®ä¼°è¨ˆï¼‰
    if trajectories:
        final_positions = trajectories[-1]['positions']
        target_center = np.mean(final_positions, axis=0)
        goal_circle = patches.Circle(target_center, goal_radius, 
                                   color='green', alpha=0.4, linestyle='--',
                                   edgecolor='darkgreen', linewidth=3,
                                   label='Target Area')
        ax.add_patch(goal_circle)
    
    # æ™ºèƒ½é«”é¡è‰²æ–¹æ¡ˆ
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f']
    
    # åˆå§‹åŒ–æ™ºèƒ½é«”å’Œè»Œè·¡
    num_agents = len(trajectories[0]['positions'])
    agent_circles = []
    trajectory_lines = []
    
    for i in range(num_agents):
        # æ™ºèƒ½é«”åœ“åœˆ
        circle = patches.Circle((0, 0), agent_radius, color=colors[i % len(colors)], 
                              alpha=0.9, edgecolor='black', linewidth=1.5,
                              label=f'Agent {i+1}' if i < 8 else "")
        ax.add_patch(circle)
        agent_circles.append(circle)
        
        # è»Œè·¡ç·š
        line, = ax.plot([], [], color=colors[i % len(colors)], alpha=0.7, linewidth=2.5)
        trajectory_lines.append(line)
    
    # æ¨™è¨˜èµ·å§‹ä½ç½®
    start_positions = trajectories[0]['positions']
    for i, pos in enumerate(start_positions):
        ax.plot(pos[0], pos[1], marker='*', color=colors[i % len(colors)], 
               markersize=15, markeredgecolor='black', markeredgewidth=2,
               label='Start Positions' if i == 0 else "")
    
    # æ·»åŠ è©³ç´°ä¿¡æ¯é¢æ¿
    info_text = ax.text(0.02, 0.98, '', transform=ax.transAxes, fontsize=12, 
                       verticalalignment='top', fontweight='bold',
                       bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", 
                               alpha=0.9, edgecolor='navy'))
    
    # æ·»åŠ æ€§èƒ½æŒ‡æ¨™é¢æ¿
    metrics_text = ax.text(0.98, 0.98, '', transform=ax.transAxes, fontsize=11, 
                          verticalalignment='top', horizontalalignment='right',
                          bbox=dict(boxstyle="round,pad=0.4", facecolor="lightgreen", 
                                  alpha=0.9, edgecolor='darkgreen'))
    
    # æ·»åŠ åœ–ä¾‹
    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=4, 
             fontsize=12, frameon=True, fancybox=True, shadow=True)
    
    def animate(frame):
        if frame >= len(trajectories):
            return agent_circles + trajectory_lines + [info_text, metrics_text]
        
        positions = trajectories[frame]['positions']
        
        # æ›´æ–°æ™ºèƒ½é«”ä½ç½®
        for i, circle in enumerate(agent_circles):
            circle.center = positions[i]
        
        # æ›´æ–°è»Œè·¡ç·š
        for i, line in enumerate(trajectory_lines):
            trajectory_x = [traj['positions'][i][0] for traj in trajectories[:frame+1]]
            trajectory_y = [traj['positions'][i][1] for traj in trajectories[:frame+1]]
            line.set_data(trajectory_x, trajectory_y)
        
        # è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
        if hasattr(ax, '_target_center'):
            target_center = ax._target_center
        else:
            target_center = np.mean(trajectories[-1]['positions'], axis=0)
            ax._target_center = target_center
        
        distances_to_goal = [np.linalg.norm(pos - target_center) for pos in positions]
        avg_distance = np.mean(distances_to_goal)
        min_distance = np.min(distances_to_goal)
        
        # è¨ˆç®—æ™ºèƒ½é«”é–“è·é›¢ï¼ˆå”ä½œæŒ‡æ¨™ï¼‰
        agent_distances = []
        for i in range(len(positions)):
            for j in range(i+1, len(positions)):
                dist = np.linalg.norm(positions[i] - positions[j])
                agent_distances.append(dist)
        min_agent_distance = np.min(agent_distances) if agent_distances else 0
        
        # æ›´æ–°ä¿¡æ¯é¢æ¿
        progress = (frame / len(trajectories)) * 100
        info_text.set_text(
            f'ğŸ“Š Simulation Progress\n'
            f'Step: {frame:3d} / {len(trajectories)}\n'
            f'Progress: {progress:5.1f}%\n'
            f'Model: 9500 steps trained'
        )
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ¨™é¢æ¿
        metrics_text.set_text(
            f'ğŸ¯ Performance Metrics\n'
            f'Avg Goal Distance: {avg_distance:.3f}m\n'
            f'Min Goal Distance: {min_distance:.3f}m\n'
            f'Min Agent Distance: {min_agent_distance:.3f}m\n'
            f'Collaboration: {"âœ…" if min_agent_distance > 0.15 else "âš ï¸"}\n'
            f'Navigation: {"âœ…" if avg_distance < 1.0 else "ğŸ”„"}'
        )
        
        return agent_circles + trajectory_lines + [info_text, metrics_text]
    
    # å‰µå»ºå‹•ç•«
    print(f"ğŸ¬ ç”Ÿæˆå‹•ç•«ï¼Œç¸½å¹€æ•¸: {len(trajectories)}")
    anim = FuncAnimation(fig, animate, frames=len(trajectories), 
                        interval=100, blit=False, repeat=True)
    
    # ä¿å­˜å‹•ç•«
    try:
        print(f"ğŸ’¾ ä¿å­˜ç‚º MP4: {save_path}")
        anim.save(save_path, writer='ffmpeg', fps=12, bitrate=3000,
                 extra_args=['-vcodec', 'libx264', '-pix_fmt', 'yuv420p'])
        print(f"âœ… MP4 ä¿å­˜æˆåŠŸ: {save_path}")
        return save_path
    except Exception as e:
        print(f"âŒ MP4 ä¿å­˜å¤±æ•—: {e}")
        # å˜—è©¦ä¿å­˜ç‚ºGIF
        gif_path = save_path.replace('.mp4', '.gif')
        try:
            print(f"ğŸ’¾ å˜—è©¦ä¿å­˜ç‚º GIF: {gif_path}")
            anim.save(gif_path, writer='pillow', fps=8)
            print(f"âœ… GIF ä¿å­˜æˆåŠŸ: {gif_path}")
            return gif_path
        except Exception as e2:
            print(f"âŒ GIF ä¿å­˜ä¹Ÿå¤±æ•—: {e2}")
            return None
    finally:
        plt.close()


def main():
    """ä¸»å‡½æ•¸ - æ¡ç”¨é›™æºé…ç½®åŠ è¼‰ç­–ç•¥"""
    print("ğŸš€ èª²ç¨‹å­¸ç¿’æœ€çµ‚å¯è¦–åŒ–")
    print("=" * 70)
    print("ğŸ“ åŸºæ–¼é›™æºé…ç½®åŠ è¼‰çš„ç©©å¥è§£æ±ºæ–¹æ¡ˆ")
    print("=" * 70)
    
    try:
        # Step 1: åŠ è¼‰åŸºç¤é…ç½®æ–‡ä»¶ï¼ˆä¿è­‰å®Œæ•´æ€§ï¼‰
        print("ğŸ”§ Step 1: åŠ è¼‰åŸºç¤é…ç½®...")
        base_config_path = 'config/alpha_medium_obs.yaml'
        with open(base_config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print(f"âœ… åŸºç¤é…ç½®åŠ è¼‰æˆåŠŸ: {base_config_path}")
        
        # Step 2: å®šç¾©æ¨¡å‹ç›®éŒ„ä¸¦åŠ è¼‰æ¨¡å‹ç‰¹å®šé…ç½®
        model_dir = "logs/bptt/models/9500"
        print(f"\nğŸ“‚ Step 2: ç›®æ¨™æ¨¡å‹: {model_dir}")
        
        # å˜—è©¦åŠ è¼‰æ¨¡å‹ç‰¹å®šé…ç½®ä¸¦åˆä½µ
        config_path = os.path.join(model_dir, "config.pt")
        if os.path.exists(config_path):
            try:
                model_config = torch.load(config_path, map_location='cpu', weights_only=False)
                # æ™ºèƒ½åˆä½µï¼šæ¨¡å‹é…ç½®è¦†è“‹åŸºç¤é…ç½®
                config.update(model_config)
                print("âœ… æ¨¡å‹é…ç½®å·²åˆä½µåˆ°åŸºç¤é…ç½®")
            except Exception as e:
                print(f"âš ï¸ æ¨¡å‹é…ç½®åŠ è¼‰å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤é…ç½®: {e}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ï¼Œä½¿ç”¨åŸºç¤é…ç½®")
        
        # Step 3: ä½¿ç”¨çµ±ä¸€å·¥å…·åŠ è¼‰ç­–ç•¥æ¨¡å‹
        print("\nğŸ”§ Step 3: åŠ è¼‰ç­–ç•¥æ¨¡å‹...")
        policy, _ = load_model_and_config(model_dir)  # å¿½ç•¥è¿”å›çš„é…ç½®ï¼Œä½¿ç”¨æˆ‘å€‘åˆä½µçš„é…ç½®
        
        # Step 4: ä½¿ç”¨ç©©å¥çš„é…ç½®å‰µå»ºç’°å¢ƒ
        print("\nğŸŒ Step 4: å‰µå»ºç’°å¢ƒ...")
        env = DoubleIntegratorEnv(config['env'])  # ç¾åœ¨ä¿è­‰åŒ…å«'env'éµ
        print(f"âœ… ç’°å¢ƒå‰µå»ºæˆåŠŸ: {env.num_agents} æ™ºèƒ½é«”")
        
        # Step 5: é‹è¡Œä»¿çœŸç²å–è»Œè·¡
        print("\nğŸ¬ Step 5: é‹è¡Œä»¿çœŸ...")
        trajectories, obstacles = run_simulation_for_visualization(env, policy, steps=250)
        
        # Step 6: å‰µå»ºæœ€çµ‚å‹•ç•«
        print("\nğŸ¨ Step 6: ç”Ÿæˆæœ€çµ‚å¯è¦–åŒ–...")
        result_path = create_final_animation(trajectories, obstacles, config)
        
        # çµæœå ±å‘Š
        if result_path:
            print("\n" + "=" * 70)
            print("ğŸ‰ èª²ç¨‹å­¸ç¿’æœ€çµ‚å¯è¦–åŒ–ç”ŸæˆæˆåŠŸï¼")
            print("=" * 70)
            print(f"ğŸ“ è¼¸å‡ºæ–‡ä»¶: {result_path}")
            print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
            print(f"   â€¢ æª¢æŸ¥é»: {model_dir}")
            print(f"   â€¢ æ™ºèƒ½é«”æ•¸é‡: {env.num_agents}")
            print(f"   â€¢ éšœç¤™ç‰©æ•¸é‡: {len(obstacles)}")
            print(f"   â€¢ è»Œè·¡é•·åº¦: {len(trajectories)} æ­¥")
            print(f"   â€¢ è¨“ç·´æ­¥æ•¸: 9500")
            print(f"   â€¢ å”ä½œèƒ½åŠ›: âœ… å¤šæ™ºèƒ½é«”å”èª¿")
            print(f"   â€¢ é¿éšœèƒ½åŠ›: âœ… å‹•æ…‹é¿éšœ")
            print(f"   â€¢ ç›®æ¨™å°èˆª: âœ… ç›®æ¨™æ”¶æ–‚")
            print("=" * 70)
            print("ğŸ¯ é€™æ˜¯æ‚¨èª²ç¨‹å­¸ç¿’æ¡†æ¶çš„æœ€çµ‚æˆæœå±•ç¤ºï¼")
        else:
            print("âŒ å¯è¦–åŒ–ç”Ÿæˆå¤±æ•—")
            
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()